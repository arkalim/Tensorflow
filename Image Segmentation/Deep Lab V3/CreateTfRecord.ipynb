{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreateTfRecord.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkalim/Tensorflow/blob/master/CreateTfRecord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw3JGKZ6vlnM",
        "colab_type": "text"
      },
      "source": [
        "# This notebook creates tf-record file to train DeepLab V3 on Pascal VOC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLRnRS62E6Lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import scipy.io as spio\n",
        "from matplotlib import pyplot as plt\n",
        "from imageio import imread"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0z3anqmFPYq",
        "colab_type": "text"
      },
      "source": [
        "# Download augmented Pascal VOC dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZK4ZaU5FBEQ",
        "colab_type": "code",
        "outputId": "c996f35c-8d97-4459-d343-c2b4fff0523c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!wget http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/semantic_contours/benchmark.tgz\n",
        "    \n",
        "import tarfile\n",
        "tf_ = tarfile.open(\"benchmark.tgz\")\n",
        "tf_.extractall()   \n",
        "\n",
        "os.remove('benchmark.tgz')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-19 04:44:39--  http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/semantic_contours/benchmark.tgz\n",
            "Resolving www.eecs.berkeley.edu (www.eecs.berkeley.edu)... 23.185.0.1, 2620:12a:8001::1, 2620:12a:8000::1\n",
            "Connecting to www.eecs.berkeley.edu (www.eecs.berkeley.edu)|23.185.0.1|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/semantic_contours/benchmark.tgz [following]\n",
            "--2019-06-19 04:44:39--  https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/semantic_contours/benchmark.tgz\n",
            "Resolving www2.eecs.berkeley.edu (www2.eecs.berkeley.edu)... 128.32.189.73\n",
            "Connecting to www2.eecs.berkeley.edu (www2.eecs.berkeley.edu)|128.32.189.73|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1419539633 (1.3G) [application/x-tar]\n",
            "Saving to: ‘benchmark.tgz’\n",
            "\n",
            "benchmark.tgz       100%[===================>]   1.32G  40.2MB/s    in 34s     \n",
            "\n",
            "2019-06-19 04:45:13 (39.8 MB/s) - ‘benchmark.tgz’ saved [1419539633/1419539633]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drXH22tQHeHJ",
        "colab_type": "text"
      },
      "source": [
        "# Define the paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rimXdlUFGMEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define base paths for pascal augmented VOC images\n",
        "# download: http://home.bharathh.info/pubs/codes/SBD/download.html\n",
        "dataset_dir = '/content/benchmark_RELEASE/dataset'\n",
        "images_dir = 'img/'\n",
        "annotations_dir = 'cls/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV0nEPBNIgGb",
        "colab_type": "code",
        "outputId": "ef5c1206-6fd2-4d47-9f40-d187f0074c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.listdir(dataset_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cls', 'img', 'val.txt', 'inst', 'train.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6sdhLXjHhai",
        "colab_type": "text"
      },
      "source": [
        "# Function to get the filenames for images and annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP-Av9UCGVkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_files_list(dataset_dir, images_folder, annotations_folder, file):\n",
        "    \n",
        "    images_dir = os.path.join(dataset_dir, images_folder)\n",
        "    annotations_dir = os.path.join(dataset_dir, annotations_folder)\n",
        "    \n",
        "    image_filenames = []\n",
        "    annotation_filenames = []\n",
        "\n",
        "    # open the text file\n",
        "    file = open(os.path.join(dataset_dir, file), 'r')\n",
        "    \n",
        "    # read each line except the last '\\n'\n",
        "    filenames = [line[:-1] for line in file]\n",
        "    \n",
        "    # shuffle the filenames\n",
        "    np.random.shuffle(filenames)\n",
        "    \n",
        "    for filename in filenames:\n",
        "        image_filenames.append(os.path.join(images_dir, ('{}.jpg'.format(filename))))\n",
        "        annotation_filenames.append(os.path.join(annotations_dir, ('{}.mat'.format(filename))))\n",
        "    \n",
        "    # return the list of filenames\n",
        "    return image_filenames, annotation_filenames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s_jdN5YHbCO",
        "colab_type": "code",
        "outputId": "a09291e5-23cb-4756-f0cf-816a718e0597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\n",
        "train_image_filenames , train_annotation_filenames = get_files_list(dataset_dir, images_dir, annotations_dir, 'train.txt')\n",
        "valid_image_filenames , valid_annotation_filenames = get_files_list(dataset_dir, images_dir, annotations_dir, 'val.txt')\n",
        "\n",
        "print(\"Train Set size:\", len(train_image_filenames))\n",
        "print(\"Valid Set size:\", len(valid_image_filenames))\n",
        "\n",
        "print(train_image_filenames[0])\n",
        "print(train_annotation_filenames[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set size: 8498\n",
            "Valid Set size: 2857\n",
            "/content/benchmark_RELEASE/dataset/img/2008_002103.jpg\n",
            "/content/benchmark_RELEASE/dataset/cls/2008_002103.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWxQ91-du9eh",
        "colab_type": "text"
      },
      "source": [
        "# Create TF Record"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlNH4K9VQWEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATASET_DIR=\"./tfrecords/\"\n",
        "\n",
        "if not os.path.exists(TRAIN_DATASET_DIR):\n",
        "    os.mkdir(TRAIN_DATASET_DIR)\n",
        "    \n",
        "TRAIN_FILE = 'train.tfrecords'\n",
        "VALIDATION_FILE = 'validation.tfrecords'\n",
        "\n",
        "train_writer = tf.python_io.TFRecordWriter(os.path.join(TRAIN_DATASET_DIR,TRAIN_FILE))\n",
        "val_writer = tf.python_io.TFRecordWriter(os.path.join(TRAIN_DATASET_DIR,VALIDATION_FILE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44h8QSKcQoXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J-OzVSwQpOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_annotation_from_mat_file(annotation_filename):\n",
        "    mat = spio.loadmat(annotation_filename)\n",
        "    img = mat['GTcls']['Segmentation'][0][0]\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMCFb8YkQxNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tfrecord_dataset(image_filenames, annotation_filenames, writer):\n",
        "\n",
        "    # create training tfrecord\n",
        "    read_imgs_counter = 0\n",
        "    \n",
        "    for i in range(len(image_filenames)):\n",
        "        \n",
        "        # read the image\n",
        "        image_np = imread(image_filenames[i])\n",
        "\n",
        "        # read the annotation\n",
        "        annotation_np = read_annotation_from_mat_file(annotation_filenames[i]) \n",
        "            \n",
        "        read_imgs_counter += 1\n",
        "        \n",
        "        # find the dimension of the image to store it for reconstruction\n",
        "        image_h = image_np.shape[0]\n",
        "        image_w = image_np.shape[1]\n",
        "\n",
        "        # convert the image and annotation to raw data (string)\n",
        "        img_raw = image_np.tostring()\n",
        "        annotation_raw = annotation_np.tostring()\n",
        "\n",
        "        # create the example for tf record\n",
        "        example = tf.train.Example(features=tf.train.Features(feature={\n",
        "            \n",
        "                'height': _int64_feature(image_h),\n",
        "                'width': _int64_feature(image_w),\n",
        "                'image_raw': _bytes_feature(img_raw),\n",
        "                'annotation_raw': _bytes_feature(annotation_raw)\n",
        "        }))\n",
        "\n",
        "        writer.write(example.SerializeToString())\n",
        "    \n",
        "    print(\"End of TfRecord. Total of image written:\", read_imgs_counter)\n",
        "    writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nix4gKCERJHy",
        "colab_type": "code",
        "outputId": "fe8246c1-d9fb-47eb-f67a-87775ed334c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "# create training dataset\n",
        "create_tfrecord_dataset(train_image_filenames, train_annotation_filenames, train_writer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 4718664 bytes but only got 0. Skipping tag 257\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 31197188 bytes but only got 0. Skipping tag 1029\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20971520 bytes but only got 0. Skipping tag 2\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 23592960 bytes but only got 0. Skipping tag 2\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 65536 bytes but only got 0. Skipping tag 3\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3604480 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 4128768 bytes but only got 0. Skipping tag 5\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 0. Skipping tag 3\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 463994880 bytes but only got 0. Skipping tag 4\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 729604 bytes but only got 7457. Skipping tag 513\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3846701056 bytes but only got 0. Skipping tag 2\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3300917248 bytes but only got 0. Skipping tag 7\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 262400 bytes but only got 7457. Skipping tag 0\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 8. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "End of TfRecord. Total of image written: 8498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi6m-G4KRXbV",
        "colab_type": "code",
        "outputId": "32bb2bb7-97e2-405d-86e6-acd3578cbcfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# create validation dataset\n",
        "create_tfrecord_dataset(valid_image_filenames, valid_annotation_filenames, val_writer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "End of TfRecord. Total of image written: 2857\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}