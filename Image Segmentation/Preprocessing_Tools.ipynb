{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing Tools.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkalim/Tensorflow/blob/master/Preprocessing_Tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmD6kEoZtGnS",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing functions for semantic segmenntation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwTSql0AVSJI",
        "colab_type": "text"
      },
      "source": [
        "## Convert a single annotated mask into one hot encoded mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBLUz_r-S6uf",
        "colab_type": "code",
        "outputId": "1467953e-a552-4394-ac37-5d0038b9dc66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "def get_labels_from_annotation(annotation_tensor, class_labels):\n",
        "    \"\"\"Returns tensor of size (width, height, num_classes) derived from annotation tensor.\n",
        "    The function returns tensor that is of a size (width, height, num_classes) which\n",
        "    is derived from annotation tensor with sizes (width, height) where value at\n",
        "    each position represents a class. The functions requires a list with class\n",
        "    values like [0, 1, 2 ,3] -- they are used to derive labels. Derived values will\n",
        "    be ordered in the same way as the class numbers were provided in the list. Last\n",
        "    value in the aforementioned list represents a value that indicate that the pixel\n",
        "    should be masked out. So, the size of num_classes := len(class_labels) - 1.\n",
        "    Parameters\n",
        "    ----------\n",
        "    annotation_tensor : Tensor of size (width, height)\n",
        "        Tensor with class labels for each element\n",
        "    class_labels : list of ints\n",
        "        List that contains the numbers that represent classes. Last\n",
        "        value in the list should represent the number that was used\n",
        "        for masking out.\n",
        "    Returns\n",
        "    -------\n",
        "    labels_2d_stacked : Tensor of size (width, height, num_classes).\n",
        "        Tensor with labels for each pixel.\n",
        "    \"\"\"\n",
        "\n",
        "    # Last value in the classes list should show\n",
        "    # which number was used in the annotation to mask out\n",
        "    # the ambigious regions or regions that should not be\n",
        "    # used for training.\n",
        "    # TODO: probably replace class_labels list with some custom object\n",
        "    valid_entries_class_labels = class_labels[:-1]\n",
        "\n",
        "    # Stack the binary masks for each class\n",
        "    labels_2d = list(map(lambda x: tf.equal(annotation_tensor, x), valid_entries_class_labels))\n",
        "\n",
        "    # Perform the merging of all of the binary masks into one matrix\n",
        "    labels_2d_stacked = tf.stack(labels_2d, axis=2)\n",
        "\n",
        "    # Convert tf.bool to tf.float\n",
        "    # Later on in the labels and logits will be used\n",
        "    # in tf.softmax_cross_entropy_with_logits() function\n",
        "    # where they have to be of the float type.\n",
        "    labels_2d_stacked_float = tf.to_float(labels_2d_stacked)\n",
        "\n",
        "    return labels_2d_stacked_float"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0617 10:58:15.271026 140583810160512 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_vjGsNhS8SM",
        "colab_type": "code",
        "outputId": "51704df3-0882-41a6-a546-c658e7e7a512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "a = tf.constant([[0,1,1,0,1,0,10,2],\n",
        "                 [0,2,1,0,2,0,2,1],\n",
        "                 [1,2,1,0,1,0,1,2],\n",
        "                 [0,0,1,0,1,0,0,2]])\n",
        "\n",
        "print(a)\n",
        "\n",
        "b = get_labels_from_annotation(a, [0,1,2,10,255])\n",
        "\n",
        "print(b)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(b.eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_1:0\", shape=(4, 8), dtype=int32)\n",
            "Tensor(\"ToFloat_1:0\", shape=(4, 8, 4), dtype=float32)\n",
            "[[[1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  [0. 0. 0. 1.]\n",
            "  [0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 1. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  [0. 0. 1. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8zclMGFVq-h",
        "colab_type": "text"
      },
      "source": [
        "## Convert a batch of annotated masks into one hot encoded masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8MgJJyOVpfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_labels_from_annotation_batch(annotation_batch_tensor, class_labels):\n",
        "    \n",
        "    \"\"\"Returns tensor of size (batch_size, width, height, num_classes) derived\n",
        "    from annotation batch tensor. The function returns tensor that is of a size\n",
        "    (batch_size, width, height, num_classes) which is derived from annotation tensor\n",
        "    with sizes (batch_size, width, height) where value at each position represents a class.\n",
        "    The functions requires a list with class values like [0, 1, 2 ,3] -- they are\n",
        "    used to derive labels. Derived values will be ordered in the same way as\n",
        "    the class numbers were provided in the list. Last value in the aforementioned\n",
        "    list represents a value that indicate that the pixel should be masked out.\n",
        "    So, the size of num_classes len(class_labels) - 1.\n",
        "    Parameters\n",
        "    ----------\n",
        "    annotation_batch_tensor : Tensor of size (batch_size, width, height)\n",
        "        Tensor with class labels for each element\n",
        "    class_labels : list of ints\n",
        "        List that contains the numbers that represent classes. Last\n",
        "        value in the list should represent the number that was used\n",
        "        for masking out.\n",
        "    Returns\n",
        "    -------\n",
        "    batch_labels : Tensor of size (batch_size, width, height, num_classes).\n",
        "        Tensor with labels for each batch.\n",
        "    \"\"\"\n",
        "\n",
        "    # map the function 'get_labels_from_annotation()' to all the elements of 'annotation_batch_tensor'\n",
        "    batch_labels = tf.map_fn(fn=lambda x: get_labels_from_annotation(annotation_tensor=x, class_labels=class_labels), elems=annotation_batch_tensor, dtype=tf.float32)\n",
        "\n",
        "    return batch_labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM7KC3y1Vg9k",
        "colab_type": "code",
        "outputId": "69981677-35c6-443b-df7c-b514a5d9e921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1990
        }
      },
      "source": [
        "a = tf.constant([[[0,1,1,0,1,0,2,2],\n",
        "                  [0,2,1,0,2,0,2,1],\n",
        "                  [1,2,1,0,1,0,1,2],\n",
        "                  [0,0,1,0,1,0,0,2]],\n",
        "                 \n",
        "                 [[0,1,1,0,1,0,2,2],\n",
        "                  [0,2,1,0,2,0,2,1],\n",
        "                  [1,2,1,0,1,0,1,2],\n",
        "                  [0,0,1,0,1,0,0,2]],\n",
        "                 \n",
        "                 [[0,1,1,0,1,0,2,2],\n",
        "                  [0,2,1,0,2,0,2,1],\n",
        "                  [1,2,1,0,1,0,1,2],\n",
        "                  [0,0,1,0,1,0,0,2]]])\n",
        "\n",
        "print(a)\n",
        "\n",
        "b = get_labels_from_annotation_batch(a, [0,1,2,255])\n",
        "\n",
        "print(b)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(b.eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_14:0\", shape=(3, 4, 8), dtype=int32)\n",
            "Tensor(\"map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(3, 4, 8, 3), dtype=float32)\n",
            "[[[[1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [0. 0. 1.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [0. 1. 0.]]\n",
            "\n",
            "  [[0. 1. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [0. 0. 1.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [0. 0. 1.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [0. 1. 0.]]\n",
            "\n",
            "  [[0. 1. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [0. 0. 1.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [0. 0. 1.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [0. 1. 0.]]\n",
            "\n",
            "  [[0. 1. 0.]\n",
            "   [0. 0. 1.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [0. 0. 1.]]\n",
            "\n",
            "  [[1. 0. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 1. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [1. 0. 0.]\n",
            "   [0. 0. 1.]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKoCb5UvgzaS",
        "colab_type": "text"
      },
      "source": [
        "## Finding the position of pixels in the annotation masks which don't belong to the last class:255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcaYcr-GaCwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_valid_entries_indices_from_annotation_batch(annotation_batch_tensor, class_labels):\n",
        "    \"\"\"\n",
        "    Returns the indices of valid entries in the annotations.Output is a tensor of size \n",
        "    (num_valid_entries, 3) if the input is of shape [batch_size, width, height] and \n",
        "    if the input is of shape [width, height] then the output is of shape [num_valid_enteries,3]\n",
        "    \n",
        "    Valid entries are those entries in the annotations that don't belong to the last class: 255\n",
        "    The last class is ambiguous and we dont't want them in our training case.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    annotation_batch_tensor : Tensor of size (batch_size, width, height)\n",
        "        Tensor with class labels for each batch\n",
        "        \n",
        "    class_labels : list of ints\n",
        "        List that contains the numbers that represent classes. Last\n",
        "        value in the list should represent the number that was used\n",
        "        for masking out.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    valid_labels_indices : \n",
        "        Tensor with indices of valid entries in row major form\n",
        "        [row, col, depth] or [row, col] depending on the input\n",
        "    \"\"\"\n",
        "\n",
        "    # Last value in the classes list should show\n",
        "    # which number was used in the annotation to mask out\n",
        "    # the ambigious regions or regions that should not be\n",
        "    # used for training.\n",
        "\n",
        "    mask_out_class_label = class_labels[-1]\n",
        "\n",
        "    # Get binary mask for the pixels that we want to\n",
        "    # use for training. We do this because some pixels\n",
        "    # are marked as ambigious and we don't want to use\n",
        "    # them for trainig to avoid confusing the model\n",
        "    valid_labels_mask = tf.not_equal(annotation_batch_tensor, mask_out_class_label)\n",
        "\n",
        "    # Search for the valid indices in row major form\n",
        "    valid_labels_indices = tf.where(valid_labels_mask)\n",
        "\n",
        "    return tf.to_int32(valid_labels_indices)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV-ED0BSdrla",
        "colab_type": "code",
        "outputId": "b6365c64-53e3-4cad-d3bb-09a3a93504e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        }
      },
      "source": [
        "# A single annotation\n",
        "a = tf.constant([[0,1,255,0,1,0,2,2],\n",
        "                 [0,2,1,0,2,0,2,1],\n",
        "                 [1,2,1,0,1,0,1,2],\n",
        "                 [0,0,1,0,1,255,0,2]])\n",
        "\n",
        "print(a)\n",
        "\n",
        "b = get_valid_entries_indices_from_annotation_batch(a, [0,1,2,255])\n",
        "\n",
        "print(b)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(b.eval().shape)\n",
        "    print(b.eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_21:0\", shape=(4, 8), dtype=int32)\n",
            "Tensor(\"ToInt32_5:0\", shape=(?, 2), dtype=int32)\n",
            "(30, 2)\n",
            "[[0 0]\n",
            " [0 1]\n",
            " [0 3]\n",
            " [0 4]\n",
            " [0 5]\n",
            " [0 6]\n",
            " [0 7]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [1 5]\n",
            " [1 6]\n",
            " [1 7]\n",
            " [2 0]\n",
            " [2 1]\n",
            " [2 2]\n",
            " [2 3]\n",
            " [2 4]\n",
            " [2 5]\n",
            " [2 6]\n",
            " [2 7]\n",
            " [3 0]\n",
            " [3 1]\n",
            " [3 2]\n",
            " [3 3]\n",
            " [3 4]\n",
            " [3 6]\n",
            " [3 7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsSqZuvEc-oi",
        "colab_type": "code",
        "outputId": "d6270865-58d9-41fb-aada-48555b742eb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1741
        }
      },
      "source": [
        "# A batch of 3 annotations\n",
        "a = tf.constant([[[0,1,1,0,1,0,2,2],\n",
        "                  [0,2,1,0,2,0,2,1],\n",
        "                  [1,2,1,0,1,0,1,2],\n",
        "                  [0,0,1,0,1,0,0,2]],\n",
        "                 \n",
        "                 [[0,1,1,0,1,0,2,2],\n",
        "                  [0,2,255,0,2,0,2,1],\n",
        "                  [1,2,1,0,1,0,1,2],\n",
        "                  [0,0,1,0,1,0,0,2]],\n",
        "                 \n",
        "                 [[0,1,1,225,1,0,2,2],\n",
        "                  [0,2,1,0,2,0,2,1],\n",
        "                  [1,2,1,0,1,0,1,2],\n",
        "                  [0,0,225,0,1,0,0,2]]])\n",
        "\n",
        "print(a)\n",
        "\n",
        "b = get_valid_entries_indices_from_annotation_batch(a, [0,1,2,225])\n",
        "\n",
        "print(b)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(b.eval().shape)\n",
        "    print(b.eval())    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_22:0\", shape=(3, 4, 8), dtype=int32)\n",
            "Tensor(\"ToInt32_6:0\", shape=(?, 3), dtype=int32)\n",
            "(94, 3)\n",
            "[[0 0 0]\n",
            " [0 0 1]\n",
            " [0 0 2]\n",
            " [0 0 3]\n",
            " [0 0 4]\n",
            " [0 0 5]\n",
            " [0 0 6]\n",
            " [0 0 7]\n",
            " [0 1 0]\n",
            " [0 1 1]\n",
            " [0 1 2]\n",
            " [0 1 3]\n",
            " [0 1 4]\n",
            " [0 1 5]\n",
            " [0 1 6]\n",
            " [0 1 7]\n",
            " [0 2 0]\n",
            " [0 2 1]\n",
            " [0 2 2]\n",
            " [0 2 3]\n",
            " [0 2 4]\n",
            " [0 2 5]\n",
            " [0 2 6]\n",
            " [0 2 7]\n",
            " [0 3 0]\n",
            " [0 3 1]\n",
            " [0 3 2]\n",
            " [0 3 3]\n",
            " [0 3 4]\n",
            " [0 3 5]\n",
            " [0 3 6]\n",
            " [0 3 7]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [1 0 2]\n",
            " [1 0 3]\n",
            " [1 0 4]\n",
            " [1 0 5]\n",
            " [1 0 6]\n",
            " [1 0 7]\n",
            " [1 1 0]\n",
            " [1 1 1]\n",
            " [1 1 2]\n",
            " [1 1 3]\n",
            " [1 1 4]\n",
            " [1 1 5]\n",
            " [1 1 6]\n",
            " [1 1 7]\n",
            " [1 2 0]\n",
            " [1 2 1]\n",
            " [1 2 2]\n",
            " [1 2 3]\n",
            " [1 2 4]\n",
            " [1 2 5]\n",
            " [1 2 6]\n",
            " [1 2 7]\n",
            " [1 3 0]\n",
            " [1 3 1]\n",
            " [1 3 2]\n",
            " [1 3 3]\n",
            " [1 3 4]\n",
            " [1 3 5]\n",
            " [1 3 6]\n",
            " [1 3 7]\n",
            " [2 0 0]\n",
            " [2 0 1]\n",
            " [2 0 2]\n",
            " [2 0 4]\n",
            " [2 0 5]\n",
            " [2 0 6]\n",
            " [2 0 7]\n",
            " [2 1 0]\n",
            " [2 1 1]\n",
            " [2 1 2]\n",
            " [2 1 3]\n",
            " [2 1 4]\n",
            " [2 1 5]\n",
            " [2 1 6]\n",
            " [2 1 7]\n",
            " [2 2 0]\n",
            " [2 2 1]\n",
            " [2 2 2]\n",
            " [2 2 3]\n",
            " [2 2 4]\n",
            " [2 2 5]\n",
            " [2 2 6]\n",
            " [2 2 7]\n",
            " [2 3 0]\n",
            " [2 3 1]\n",
            " [2 3 3]\n",
            " [2 3 4]\n",
            " [2 3 5]\n",
            " [2 3 6]\n",
            " [2 3 7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZdD7R_MhMQ3",
        "colab_type": "text"
      },
      "source": [
        "## Extract the valid pixels from logits and labels to apply softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2BtypGlhM2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_valid_logits_and_labels(annotation_batch_tensor, logits_batch_tensor, class_labels):\n",
        "    \"\"\"Returns two tensors of size (num_valid_entries, num_classes).\n",
        "    The function converts annotation batch tensor input of the size\n",
        "    (batch_size, height, width) into label tensor (batch_size, height,\n",
        "    width, num_classes) and then selects only valid entries, resulting\n",
        "    in tensor of the size (num_valid_entries, num_classes). The function\n",
        "    also returns the tensor with corresponding valid entries in the logits\n",
        "    tensor. Overall, two tensors of the same sizes are returned and later on\n",
        "    can be used as an input into tf.softmax_cross_entropy_with_logits() to\n",
        "    get the cross entropy error for each entry.\n",
        "    Parameters\n",
        "    ----------\n",
        "    annotation_batch_tensor : Tensor of size (batch_size, width, height)\n",
        "        Tensor with class labels for each batch\n",
        "    logits_batch_tensor : Tensor of size (batch_size, width, height, num_classes)\n",
        "        Tensor with logits. Usually can be achived after inference of fcn network.\n",
        "    class_labels : list of ints\n",
        "        List that contains the numbers that represent classes. Last\n",
        "        value in the list should represent the number that was used\n",
        "        for masking out.\n",
        "    Returns\n",
        "    -------\n",
        "    (valid_labels_batch_tensor, valid_logits_batch_tensor) : Two Tensors of size (num_valid_eintries, num_classes).\n",
        "        Tensors that represent valid labels and logits.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert annotations into one hot encoded labels\n",
        "    labels_batch_tensor = get_labels_from_annotation_batch(annotation_batch_tensor=annotation_batch_tensor, class_labels=class_labels)\n",
        "    \n",
        "    # get the indexes of valid pixels in annotations\n",
        "    valid_batch_indices = get_valid_entries_indices_from_annotation_batch(annotation_batch_tensor=annotation_batch_tensor, class_labels=class_labels)\n",
        "\n",
        "    # Select the valid pixels from labels\n",
        "    valid_labels_batch_tensor = tf.gather_nd(params=labels_batch_tensor, indices=valid_batch_indices)\n",
        "\n",
        "    # Select the valid pixels from logits \n",
        "    valid_logits_batch_tensor = tf.gather_nd(params=logits_batch_tensor, indices=valid_batch_indices)\n",
        "\n",
        "    return valid_labels_batch_tensor, valid_logits_batch_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1eUelBdlbEZ",
        "colab_type": "code",
        "outputId": "1395a69b-85bc-4b81-fa64-8984c05bf964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# A batch of 3 annotations\n",
        "a = tf.constant([[[0,1,1,0,1,0,2,2],\n",
        "                  [0,2,1,0,2,0,2,1],\n",
        "                  [1,2,1,0,1,0,1,2],\n",
        "                  [0,0,1,0,1,0,0,2]],\n",
        "                 \n",
        "                 [[0,1,1,0,1,0,2,2],\n",
        "                  [0,2,255,0,2,0,2,1],\n",
        "                  [1,2,1,0,1,0,1,2],\n",
        "                  [0,0,1,0,1,0,0,2]],\n",
        "                 \n",
        "                 [[0,1,1,225,1,0,2,2],\n",
        "                  [0,2,1,0,2,0,2,1],\n",
        "                  [1,2,1,0,1,0,1,2],\n",
        "                  [0,0,225,0,1,0,0,2]]])\n",
        "\n",
        "print(a)\n",
        "\n",
        "# A batch of 3 annotations\n",
        "b = tf.constant([[[0,1,1,0,1,0,2,2],\n",
        "                  [0,2,1,0,2,0,2,1],\n",
        "                  [1,2,1,0,1,0,1,2],\n",
        "                  [0,0,1,0,1,0,0,2]],\n",
        "                 \n",
        "                 [[0,1,1,0,1,0,2,2],\n",
        "                  [0,2,255,0,255,0,2,1],\n",
        "                  [1,2,1,0,1,0,1,2],\n",
        "                  [0,0,1,0,1,0,0,2]],\n",
        "                 \n",
        "                 [[0,1,1,225,1,0,2,2],\n",
        "                  [0,2,1,0,2,0,2,1],\n",
        "                  [1,2,1,0,1,0,1,2],\n",
        "                  [0,0,225,0,1,0,0,2]]])\n",
        "\n",
        "b_categorical = get_labels_from_annotation_batch(b, [0,1,2,255])\n",
        "\n",
        "print(b)\n",
        "\n",
        "c,d = get_valid_logits_and_labels(a, b_categorical, [0,1,2,225])\n",
        "\n",
        "print(c)\n",
        "print(d)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(c.eval().shape)\n",
        "    print(d.eval().shape) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Const_29:0\", shape=(3, 4, 8), dtype=int32)\n",
            "Tensor(\"Const_30:0\", shape=(3, 4, 8), dtype=int32)\n",
            "Tensor(\"GatherNd_6:0\", shape=(?, 3), dtype=float32)\n",
            "Tensor(\"GatherNd_7:0\", shape=(?, 3), dtype=float32)\n",
            "(94, 3)\n",
            "(94, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}