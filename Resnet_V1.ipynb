{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet V1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkalim/Tensorflow-/blob/master/Resnet_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fku7FduVfgS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the required packages\n",
        "import tensorflow as tf \n",
        "import datetime, os\n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow.contrib.layers as layers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.examples.tutorials import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Now we load the mnist dataset\n",
        "# each handwritten digit is of the size 28*28 i.e. 784 pixels grayscale image\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# we use one hot encoding for labels\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "# 55000 examples with grayscale image of 784 pixels (images are already flattened)\n",
        "print(mnist.train.images.shape)\n",
        "# the labels are one hot encoded\n",
        "print(mnist.train.labels.shape)\n",
        "# 10000 test examples\n",
        "print(mnist.test.images.shape)\n",
        "print(mnist.test.labels.shape)\n",
        "\n",
        "# Fetch the validation data and normalize it\n",
        "# Training data will be normalized after fetching the batch of training data\n",
        "X_valid = mnist.test.images\n",
        "X_valid = MinMaxScaler(feature_range=(0, 1)).fit_transform(X_valid)\n",
        "X_valid = np.reshape(X_valid,[-1,28,28,1])\n",
        "Y_valid = mnist.test.labels\n",
        "\n",
        "# Empty lists for storing the loss and accuracy history\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "validation_acc = []\n",
        "validation_loss = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8Ygdh8SgtrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "\n",
        "_BATCH_NORM_DECAY = 0.997\n",
        "_BATCH_NORM_EPSILON = 1e-5\n",
        "\n",
        "################################################################################\n",
        "# Helper Functions\n",
        "################################################################################\n",
        "\n",
        "# Performs a batch normalization using a standard set of parameters.\n",
        "def batch_norm(inputs, training, name = 'batch_norm'):\n",
        "    with tf.name_scope(name):\n",
        "        # here axis = 3 (channel last format)\n",
        "        return tf.compat.v1.layers.batch_normalization(\n",
        "            inputs=inputs, axis=3,\n",
        "            momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, center=True,\n",
        "            scale=True, training=training, fused=True, reuse = False)\n",
        "\n",
        "def maxpool_2d(inputs, kernel = 2, stride = 2, name = 'maxpool_2d'):\n",
        "    with tf.name_scope(name):\n",
        "        return tf.nn.max_pool(inputs, ksize=[1, kernel, kernel, 1], strides=[1, stride, stride, 1], padding='SAME')\n",
        "\n",
        "\n",
        "def fixed_padding(inputs, kernel_size, name = 'fixed_padding'):\n",
        "    \"\"\"Pads the input along the spatial dimensions independently of input size.\n",
        "    Args:\n",
        "        inputs: A tensor of size [batch, height_in, width_in, channels]\n",
        "        \n",
        "        kernel_size: The kernel size for conv2d or max_pool2d operation\n",
        "                 \n",
        "    Returns:\n",
        "        A tensor with the same format as the input with the data either intact\n",
        "        (if kernel_size == 1) or padded (if kernel_size > 1)\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "        \n",
        "        pad_total = kernel_size - 1\n",
        "        pad_beg = pad_total // 2\n",
        "        pad_end = pad_total - pad_beg\n",
        "\n",
        "        padded_inputs = tf.pad(tensor=inputs, paddings=[[0, 0], [pad_beg, pad_end], [pad_beg, pad_end], [0, 0]])\n",
        "        return padded_inputs\n",
        "\n",
        "def conv2d_fixed_padding(inputs, filters, kernel_size, strides, name = 'conv2d_fp'):\n",
        "    \n",
        "    with tf.name_scope(name):\n",
        "        # inputs will be of shape [-1,row,col,filters_in]\n",
        "        filters_in = int(inputs.shape[3])\n",
        "\n",
        "        # if stride > 1 then pad the input with the kernel size to obtain fixed padding\n",
        "        if strides > 1:\n",
        "            inputs = fixed_padding(inputs, kernel_size)\n",
        "\n",
        "        w = tf.Variable(tf.truncated_normal([kernel_size, kernel_size, filters_in, filters], stddev=0.1), name=\"W\")\n",
        "\n",
        "        output = tf.nn.conv2d(inputs, w, strides=[1, strides, strides, 1], padding=('SAME' if strides == 1 else 'VALID'))\n",
        "        \n",
        "        # histogram summary for tensorboard\n",
        "        tf.summary.histogram(\"weights\", w)\n",
        "        tf.summary.histogram(\"activations\", output)    \n",
        "\n",
        "        return output  \n",
        "\n",
        "################################################################################\n",
        "# ResNet block definitions.\n",
        "################################################################################\n",
        "def bottleneck_block(inputs, filters, training, projection_shortcut, strides, name = 'bottleneck'):\n",
        "    \"\"\"A single block for ResNet v1, with a bottleneck.\n",
        "    Similar to _building_block_v1(), except using the \"bottleneck\" blocks.\n",
        "    Convolution then batch normalization then ReLU.\n",
        "      \n",
        "    Args:\n",
        "        inputs: A tensor of size [batch, height_in, width_in, channels]\n",
        "        \n",
        "        filters: The number of filters for the convolutions.\n",
        "        \n",
        "        training: A Boolean for whether the model is in training or inference\n",
        "                    mode. Needed for batch normalization.\n",
        "                    \n",
        "        projection_shortcut: The function to use for projection shortcuts\n",
        "                        (typically a 1x1 convolution when downsampling the input).\n",
        "                        \n",
        "        strides: The block's stride. If greater than 1, this block will ultimately\n",
        "                 downsample the input.\n",
        "    Returns:\n",
        "        The output tensor of the block; shape should match inputs.\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "        shortcut = inputs\n",
        "\n",
        "        if projection_shortcut is not None:\n",
        "            shortcut = projection_shortcut(inputs)\n",
        "            shortcut = batch_norm(inputs=shortcut, training=training)\n",
        "\n",
        "        inputs = conv2d_fixed_padding(inputs = inputs, filters = filters, kernel_size=1, strides=1)\n",
        "        inputs = batch_norm(inputs, training)\n",
        "        inputs = tf.nn.relu(inputs)\n",
        "\n",
        "        inputs = conv2d_fixed_padding(inputs = inputs, filters = filters, kernel_size=3, strides=strides)\n",
        "        inputs = batch_norm(inputs, training)\n",
        "        inputs = tf.nn.relu(inputs)\n",
        "\n",
        "        inputs = conv2d_fixed_padding(inputs = inputs, filters = 4 * filters, kernel_size=1, strides=1)\n",
        "        inputs = batch_norm(inputs, training)\n",
        "\n",
        "        inputs += shortcut\n",
        "        output = tf.nn.relu(inputs)\n",
        "\n",
        "        return output\n",
        "\n",
        "def stage(inputs, filters, blocks, strides, training, name = 'stage'):\n",
        "    \"\"\"Creates one layer of blocks for the ResNet model.\n",
        "    Args:\n",
        "        inputs: A tensor of size [batch, height_in, width_in, channels]\n",
        "        \n",
        "        filters: The number of filters for the first convolution of the layer\n",
        "        \n",
        "        blocks: The number of blocks contained in the layer.\n",
        "        \n",
        "        strides: The stride to use for the first convolution of the layer. If greater than 1, \n",
        "                 this layer will ultimately downsample the input.\n",
        "                 \n",
        "        training: Boolean, whether we are currently training the model. Needed for batch norm.\n",
        "        \n",
        "        name: A string name for the tensor output of the block layer.\n",
        " \n",
        "    Returns:\n",
        "        The output tensor of the block layer.\n",
        "    \"\"\"\n",
        "    \n",
        "    with tf.name_scope(name):\n",
        "\n",
        "        # Bottleneck blocks end with 4 x filters \n",
        "        filters_out = filters * 4 \n",
        "\n",
        "        def projection_shortcut(inputs):\n",
        "            with tf.name_scope('projection_shortcut'):           \n",
        "                # here number of filters = filters_out to match the shape of the output\n",
        "                return conv2d_fixed_padding(inputs = inputs, filters = filters_out, kernel_size = 1, strides = strides)\n",
        "\n",
        "        # we can make the entire resnet model using bottleneck blocks by selecting block_fn as bottleneck_block\n",
        "\n",
        "        # Only the first block per block_layer uses projection_shortcut and strides\n",
        "        inputs = bottleneck_block(inputs, filters, training, projection_shortcut, strides, name = 'block_1')\n",
        "\n",
        "        for i in range(1, blocks):\n",
        "            # other blocks in a layer do not use projecting shortcuts and they use stride = 1\n",
        "            inputs = bottleneck_block(inputs, filters, training, projection_shortcut = None, strides = 1, name = 'block_{}'.format(i+1))\n",
        "\n",
        "        # Naming the output tensor    \n",
        "        output = tf.identity(inputs, name + '_out')  \n",
        "\n",
        "        return output\n",
        "\n",
        "class Model(object):\n",
        "# Base class for building the Resnet Model\n",
        "\n",
        "    def __init__(self, num_classes, num_filters,kernel_size,conv_stride, first_pool_size, first_pool_stride, block_sizes, block_strides):\n",
        "        \n",
        "        \"\"\"Creates a model for classifying an image.\n",
        "        Args:\n",
        "\n",
        "            num_classes: The number of classes used as labels.\n",
        "      \n",
        "            num_filters: The number of filters to use for the first block layer of the model. \n",
        "                   This number is then doubled for each subsequent block layer\n",
        "                   \n",
        "            kernel_size: The kernel size to use for convolution.\n",
        "      \n",
        "            conv_stride: stride size for the initial convolutional layer\n",
        "      \n",
        "            first_pool_size: Pool size to be used for the first pooling layer.\n",
        "                       If none, the first pooling layer is skipped.\n",
        "                       \n",
        "            first_pool_stride: stride size for the first pooling layer. \n",
        "                         Not used if first_pool_size is None.\n",
        "                         \n",
        "            block_sizes: A list containing n values, where n is the number of sets of\n",
        "                   block layers desired. Each value should be the number of blocks in the i-th set.\n",
        "        \n",
        "            block_strides: List of integers representing the desired stride size for\n",
        "                     each of the sets of block layers. Should be same length as block_sizes.\n",
        "        \"\"\"\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.conv_stride = conv_stride\n",
        "        self.first_pool_size = first_pool_size\n",
        "        self.first_pool_stride = first_pool_stride\n",
        "        self.block_sizes = block_sizes\n",
        "        self.block_strides = block_strides\n",
        "\n",
        "    def __call__(self, inputs, training):\n",
        "        \"\"\"Add operations to classify a batch of input images.\n",
        "        Args:\n",
        "            inputs: A Tensor representing a batch of input images.\n",
        "            \n",
        "            training: A boolean. Set to True to add operations required only when\n",
        "                      training the classifier.\n",
        "        Returns:\n",
        "            A logits Tensor with shape [<batch_size>, self.num_classes].\n",
        "        \"\"\"\n",
        "\n",
        "        with tf.name_scope('model'):\n",
        "            \n",
        "            ######################################### Stage:1 ##########################################\n",
        "            with tf.name_scope('stage_1'):\n",
        "            \n",
        "                inputs = conv2d_fixed_padding(inputs=inputs, filters=self.num_filters, kernel_size=self.kernel_size, strides=self.conv_stride)\n",
        "                inputs = tf.identity(inputs, 'initial_conv')\n",
        "                inputs = batch_norm(inputs, training)\n",
        "                inputs = tf.nn.relu(inputs)\n",
        "\n",
        "                if self.first_pool_size:\n",
        "                    inputs = tf.compat.v1.layers.max_pooling2d(inputs=inputs, pool_size=self.first_pool_size, strides=self.first_pool_stride, padding='SAME')\n",
        "                    inputs = tf.identity(inputs, 'initial_max_pool')\n",
        "            \n",
        "            ######################################### Stage:2-n ##########################################\n",
        "            for i, num_blocks in enumerate(self.block_sizes):\n",
        "                  \n",
        "                num_filters = self.num_filters * (2**i)\n",
        "                inputs = stage(inputs=inputs, filters = num_filters, blocks=num_blocks, strides=self.block_strides[i], training = training, name='stage_{}'.format(i + 2))\n",
        "            \n",
        "            ######################################### Final Stage #######################################\n",
        "            \n",
        "            with tf.name_scope('stage_{}'.format(len(self.block_sizes)+2)):\n",
        "                \n",
        "                # axis of pooling as we use channel last\n",
        "                axes = [1, 2]\n",
        "\n",
        "                # average pooling is the same as reduce_mean\n",
        "                inputs = tf.reduce_mean(input_tensor = inputs, axis=axes, keepdims = True)\n",
        "                inputs = tf.identity(inputs, 'final_reduce_mean')\n",
        "\n",
        "                inputs = tf.squeeze(inputs, axes)\n",
        "                inputs = tf.compat.v1.layers.dense(inputs=inputs, units = self.num_classes)\n",
        "                output = tf.identity(inputs, 'final_dense')\n",
        "                return output    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFRdQHiAIhc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet_model = Model( num_classes = 10, num_filters = 64,\n",
        "               kernel_size = 7, conv_stride = 2, first_pool_size = 3, first_pool_stride = 2,\n",
        "               block_sizes = [3,4,6,3], block_strides =[1,2,2,2])\n",
        "\n",
        "reduced_model = Model( num_classes = 10, num_filters = 64,\n",
        "               kernel_size = 3, conv_stride = 1, first_pool_size = 2, first_pool_stride = 2,\n",
        "               block_sizes = [2,2,2], block_strides =[1,2,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REo8aF33MzQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"Placeholders\"):    \n",
        "    # Defining the features and labels placeholders\n",
        "    X = tf.placeholder(tf.float32 ,shape = [None ,28,28,1] , name='X')\n",
        "    Y = tf.placeholder(tf.float32,shape = [None , 10], name='Y')\n",
        "    train = tf.placeholder(tf.bool, name = 'train')\n",
        " \n",
        "# Create the CNN model\n",
        "# keep_prob is the probability to keep a node during training\n",
        "pred = reduced_model(X, train)\n",
        "\n",
        "with tf.name_scope(\"Loss\"):    \n",
        "    # Defining the loss function\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=Y))\n",
        "    tf.summary.scalar(\"Loss\",loss)\n",
        "\n",
        "with tf.name_scope(\"Optimizer\"):\n",
        "    # Defining the optimization function\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.00001).minimize(loss)\n",
        "\n",
        "with tf.name_scope(\"Accuracy\"):    \n",
        "    # The prediction is correct when Y equals pred\n",
        "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
        "\n",
        "    # Defining the accuracy\n",
        "    # Type casting the prediction to float value and averaging over the entire set\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    tf.summary.scalar(\"Accuracy\",accuracy)\n",
        "\n",
        "with tf.name_scope(\"Initializer\"):    \n",
        "    # Defining the variable initialisation function\n",
        "    init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztNPWDBdH0_v",
        "colab_type": "code",
        "outputId": "2432fe5d-c69d-4a85-a8de-6579d6372920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6131
        }
      },
      "source": [
        "#!pip install -q tf-nightly-2.0-preview\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard\n",
        "\n",
        "print('Trainable Parameters: {}'.format(len(tf.trainable_variables())))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    # Initialise the variables\n",
        "    sess.run(init)\n",
        "    \n",
        "    # Clear any prior data in logs\n",
        "    !rm -rf 'logs'\n",
        "    \n",
        "    # create a train summary writer\n",
        "    writer = tf.summary.FileWriter('logs' , sess.graph)\n",
        "\n",
        "    # Load Tensorboard at the two directories\n",
        "    #%tensorboard --logdir 'logs'\n",
        "\n",
        "    for step in range(50000):\n",
        "        \n",
        "        # Fetching the next batch of data\n",
        "        batch_x, batch_y = mnist.train.next_batch(4)\n",
        "        \n",
        "        # Normalising the data\n",
        "        batch_x = MinMaxScaler(feature_range=(0, 1)).fit_transform(batch_x)\n",
        "        \n",
        "        batch_x = np.reshape(batch_x,[-1,28,28,1])\n",
        "        \n",
        "        # Train our model on the batch of data\n",
        "        sess.run(optimizer, feed_dict={X : batch_x , Y : batch_y , train : True})\n",
        "        \n",
        "        # Displaying the loss and accuracy\n",
        "        if step % 100 == 0:\n",
        "            \n",
        "            # Evaluate the train loss and accuracy with no dropout\n",
        "            loss_train, acc_train = sess.run([loss , accuracy], feed_dict={X: batch_x,Y: batch_y, train : False})\n",
        "\n",
        "    \n",
        "            # Evaluate the test accuracy with no dropout\n",
        "            loss_valid, acc_valid = sess.run([loss , accuracy], feed_dict={X: X_valid, Y: Y_valid, train : False})\n",
        "    \n",
        "            print (\"Epoch \" + str(step) + \", Train Loss= \" + \"{:.2f}\".format(loss_train) + \", Training Accuracy= \" + \"{:.2f}\".format(acc_train) + \", Validation Loss= \" + \"{:.2f}\".format(loss_valid)+ \", Validation Accuracy:\" + \"{:.2f}\".format(acc_valid))\n",
        "    \n",
        "            # Append the data for plotting\n",
        "            train_loss.append(loss_train)\n",
        "            train_acc.append(acc_train)\n",
        "            validation_acc.append(acc_valid)\n",
        "            validation_loss.append(loss_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 16600, Train Loss= 6.25, Training Accuracy= 0.00, Validation Loss= 3.26, Validation Accuracy:0.11\n",
            "Epoch 16700, Train Loss= 3.41, Training Accuracy= 0.00, Validation Loss= 3.27, Validation Accuracy:0.10\n",
            "Epoch 16800, Train Loss= 4.53, Training Accuracy= 0.00, Validation Loss= 3.23, Validation Accuracy:0.11\n",
            "Epoch 16900, Train Loss= 3.41, Training Accuracy= 0.00, Validation Loss= 3.24, Validation Accuracy:0.10\n",
            "Epoch 17000, Train Loss= 2.66, Training Accuracy= 0.25, Validation Loss= 3.22, Validation Accuracy:0.11\n",
            "Epoch 17100, Train Loss= 1.85, Training Accuracy= 0.50, Validation Loss= 3.28, Validation Accuracy:0.13\n",
            "Epoch 17200, Train Loss= 3.92, Training Accuracy= 0.25, Validation Loss= 3.31, Validation Accuracy:0.12\n",
            "Epoch 17300, Train Loss= 3.35, Training Accuracy= 0.00, Validation Loss= 3.35, Validation Accuracy:0.11\n",
            "Epoch 17400, Train Loss= 2.67, Training Accuracy= 0.50, Validation Loss= 3.30, Validation Accuracy:0.12\n",
            "Epoch 17500, Train Loss= 3.55, Training Accuracy= 0.25, Validation Loss= 3.25, Validation Accuracy:0.11\n",
            "Epoch 17600, Train Loss= 4.43, Training Accuracy= 0.00, Validation Loss= 3.25, Validation Accuracy:0.11\n",
            "Epoch 17700, Train Loss= 2.27, Training Accuracy= 0.00, Validation Loss= 3.30, Validation Accuracy:0.11\n",
            "Epoch 17800, Train Loss= 3.77, Training Accuracy= 0.00, Validation Loss= 3.33, Validation Accuracy:0.10\n",
            "Epoch 17900, Train Loss= 1.97, Training Accuracy= 0.25, Validation Loss= 3.29, Validation Accuracy:0.11\n",
            "Epoch 18000, Train Loss= 2.10, Training Accuracy= 0.00, Validation Loss= 3.28, Validation Accuracy:0.10\n",
            "Epoch 18100, Train Loss= 5.38, Training Accuracy= 0.00, Validation Loss= 3.27, Validation Accuracy:0.11\n",
            "Epoch 18200, Train Loss= 2.60, Training Accuracy= 0.25, Validation Loss= 3.25, Validation Accuracy:0.10\n",
            "Epoch 18300, Train Loss= 1.33, Training Accuracy= 0.50, Validation Loss= 3.27, Validation Accuracy:0.12\n",
            "Epoch 18400, Train Loss= 5.00, Training Accuracy= 0.00, Validation Loss= 3.30, Validation Accuracy:0.12\n",
            "Epoch 18500, Train Loss= 5.24, Training Accuracy= 0.00, Validation Loss= 3.34, Validation Accuracy:0.13\n",
            "Epoch 18600, Train Loss= 2.74, Training Accuracy= 0.25, Validation Loss= 3.33, Validation Accuracy:0.15\n",
            "Epoch 18700, Train Loss= 4.13, Training Accuracy= 0.00, Validation Loss= 3.29, Validation Accuracy:0.14\n",
            "Epoch 18800, Train Loss= 3.01, Training Accuracy= 0.25, Validation Loss= 3.28, Validation Accuracy:0.12\n",
            "Epoch 18900, Train Loss= 3.11, Training Accuracy= 0.00, Validation Loss= 3.35, Validation Accuracy:0.10\n",
            "Epoch 19000, Train Loss= 1.83, Training Accuracy= 0.50, Validation Loss= 3.40, Validation Accuracy:0.11\n",
            "Epoch 19100, Train Loss= 2.87, Training Accuracy= 0.25, Validation Loss= 3.40, Validation Accuracy:0.11\n",
            "Epoch 19200, Train Loss= 3.67, Training Accuracy= 0.25, Validation Loss= 3.39, Validation Accuracy:0.10\n",
            "Epoch 19300, Train Loss= 2.68, Training Accuracy= 0.25, Validation Loss= 3.36, Validation Accuracy:0.10\n",
            "Epoch 19400, Train Loss= 2.57, Training Accuracy= 0.25, Validation Loss= 3.38, Validation Accuracy:0.12\n",
            "Epoch 19500, Train Loss= 4.23, Training Accuracy= 0.00, Validation Loss= 3.30, Validation Accuracy:0.16\n",
            "Epoch 19600, Train Loss= 3.44, Training Accuracy= 0.50, Validation Loss= 3.30, Validation Accuracy:0.12\n",
            "Epoch 19700, Train Loss= 3.21, Training Accuracy= 0.25, Validation Loss= 3.32, Validation Accuracy:0.11\n",
            "Epoch 19800, Train Loss= 3.68, Training Accuracy= 0.00, Validation Loss= 3.32, Validation Accuracy:0.15\n",
            "Epoch 19900, Train Loss= 2.77, Training Accuracy= 0.25, Validation Loss= 3.30, Validation Accuracy:0.15\n",
            "Epoch 20000, Train Loss= 2.11, Training Accuracy= 0.00, Validation Loss= 3.34, Validation Accuracy:0.12\n",
            "Epoch 20100, Train Loss= 3.99, Training Accuracy= 0.00, Validation Loss= 3.30, Validation Accuracy:0.12\n",
            "Epoch 20200, Train Loss= 2.26, Training Accuracy= 0.00, Validation Loss= 3.39, Validation Accuracy:0.11\n",
            "Epoch 20300, Train Loss= 3.99, Training Accuracy= 0.25, Validation Loss= 3.39, Validation Accuracy:0.12\n",
            "Epoch 20400, Train Loss= 2.09, Training Accuracy= 0.25, Validation Loss= 3.37, Validation Accuracy:0.18\n",
            "Epoch 20500, Train Loss= 4.25, Training Accuracy= 0.00, Validation Loss= 3.37, Validation Accuracy:0.21\n",
            "Epoch 20600, Train Loss= 4.08, Training Accuracy= 0.25, Validation Loss= 3.38, Validation Accuracy:0.22\n",
            "Epoch 20700, Train Loss= 3.43, Training Accuracy= 0.25, Validation Loss= 3.32, Validation Accuracy:0.20\n",
            "Epoch 20800, Train Loss= 4.02, Training Accuracy= 0.00, Validation Loss= 3.30, Validation Accuracy:0.19\n",
            "Epoch 20900, Train Loss= 4.70, Training Accuracy= 0.00, Validation Loss= 3.29, Validation Accuracy:0.21\n",
            "Epoch 21000, Train Loss= 2.88, Training Accuracy= 0.00, Validation Loss= 3.30, Validation Accuracy:0.21\n",
            "Epoch 21100, Train Loss= 3.38, Training Accuracy= 0.25, Validation Loss= 3.28, Validation Accuracy:0.20\n",
            "Epoch 21200, Train Loss= 4.40, Training Accuracy= 0.00, Validation Loss= 3.26, Validation Accuracy:0.18\n",
            "Epoch 21300, Train Loss= 3.67, Training Accuracy= 0.25, Validation Loss= 3.26, Validation Accuracy:0.13\n",
            "Epoch 21400, Train Loss= 4.24, Training Accuracy= 0.00, Validation Loss= 3.32, Validation Accuracy:0.21\n",
            "Epoch 21500, Train Loss= 4.96, Training Accuracy= 0.25, Validation Loss= 3.32, Validation Accuracy:0.18\n",
            "Epoch 21600, Train Loss= 3.13, Training Accuracy= 0.00, Validation Loss= 3.33, Validation Accuracy:0.19\n",
            "Epoch 21700, Train Loss= 2.87, Training Accuracy= 0.50, Validation Loss= 3.33, Validation Accuracy:0.13\n",
            "Epoch 21800, Train Loss= 1.61, Training Accuracy= 0.25, Validation Loss= 3.29, Validation Accuracy:0.12\n",
            "Epoch 21900, Train Loss= 3.41, Training Accuracy= 0.00, Validation Loss= 3.32, Validation Accuracy:0.15\n",
            "Epoch 22000, Train Loss= 3.07, Training Accuracy= 0.25, Validation Loss= 3.33, Validation Accuracy:0.12\n",
            "Epoch 22100, Train Loss= 2.67, Training Accuracy= 0.00, Validation Loss= 3.36, Validation Accuracy:0.11\n",
            "Epoch 22200, Train Loss= 4.78, Training Accuracy= 0.00, Validation Loss= 3.36, Validation Accuracy:0.11\n",
            "Epoch 22300, Train Loss= 4.21, Training Accuracy= 0.00, Validation Loss= 3.38, Validation Accuracy:0.10\n",
            "Epoch 22400, Train Loss= 4.83, Training Accuracy= 0.00, Validation Loss= 3.39, Validation Accuracy:0.13\n",
            "Epoch 22500, Train Loss= 5.44, Training Accuracy= 0.00, Validation Loss= 3.37, Validation Accuracy:0.13\n",
            "Epoch 22600, Train Loss= 2.92, Training Accuracy= 0.25, Validation Loss= 3.29, Validation Accuracy:0.12\n",
            "Epoch 22700, Train Loss= 4.35, Training Accuracy= 0.25, Validation Loss= 3.32, Validation Accuracy:0.11\n",
            "Epoch 22800, Train Loss= 4.38, Training Accuracy= 0.25, Validation Loss= 3.25, Validation Accuracy:0.11\n",
            "Epoch 22900, Train Loss= 2.37, Training Accuracy= 0.00, Validation Loss= 3.21, Validation Accuracy:0.12\n",
            "Epoch 23000, Train Loss= 4.38, Training Accuracy= 0.00, Validation Loss= 3.23, Validation Accuracy:0.14\n",
            "Epoch 23100, Train Loss= 4.91, Training Accuracy= 0.00, Validation Loss= 3.25, Validation Accuracy:0.11\n",
            "Epoch 23200, Train Loss= 3.40, Training Accuracy= 0.00, Validation Loss= 3.26, Validation Accuracy:0.13\n",
            "Epoch 23300, Train Loss= 2.89, Training Accuracy= 0.00, Validation Loss= 3.27, Validation Accuracy:0.12\n",
            "Epoch 23400, Train Loss= 4.42, Training Accuracy= 0.00, Validation Loss= 3.30, Validation Accuracy:0.11\n",
            "Epoch 23500, Train Loss= 4.53, Training Accuracy= 0.00, Validation Loss= 3.25, Validation Accuracy:0.12\n",
            "Epoch 23600, Train Loss= 3.27, Training Accuracy= 0.00, Validation Loss= 3.23, Validation Accuracy:0.12\n",
            "Epoch 23700, Train Loss= 2.22, Training Accuracy= 0.25, Validation Loss= 3.29, Validation Accuracy:0.13\n",
            "Epoch 23800, Train Loss= 3.08, Training Accuracy= 0.00, Validation Loss= 3.31, Validation Accuracy:0.15\n",
            "Epoch 23900, Train Loss= 1.68, Training Accuracy= 0.25, Validation Loss= 3.36, Validation Accuracy:0.14\n",
            "Epoch 24000, Train Loss= 5.14, Training Accuracy= 0.00, Validation Loss= 3.35, Validation Accuracy:0.14\n",
            "Epoch 24100, Train Loss= 2.47, Training Accuracy= 0.00, Validation Loss= 3.31, Validation Accuracy:0.11\n",
            "Epoch 24200, Train Loss= 1.87, Training Accuracy= 0.25, Validation Loss= 3.29, Validation Accuracy:0.13\n",
            "Epoch 24300, Train Loss= 2.49, Training Accuracy= 0.25, Validation Loss= 3.37, Validation Accuracy:0.16\n",
            "Epoch 24400, Train Loss= 2.89, Training Accuracy= 0.25, Validation Loss= 3.35, Validation Accuracy:0.16\n",
            "Epoch 24500, Train Loss= 3.94, Training Accuracy= 0.00, Validation Loss= 3.43, Validation Accuracy:0.13\n",
            "Epoch 24600, Train Loss= 4.79, Training Accuracy= 0.00, Validation Loss= 3.44, Validation Accuracy:0.10\n",
            "Epoch 24700, Train Loss= 5.07, Training Accuracy= 0.00, Validation Loss= 3.40, Validation Accuracy:0.11\n",
            "Epoch 24800, Train Loss= 3.50, Training Accuracy= 0.00, Validation Loss= 3.36, Validation Accuracy:0.10\n",
            "Epoch 24900, Train Loss= 5.09, Training Accuracy= 0.00, Validation Loss= 3.35, Validation Accuracy:0.10\n",
            "Epoch 25000, Train Loss= 3.37, Training Accuracy= 0.00, Validation Loss= 3.39, Validation Accuracy:0.11\n",
            "Epoch 25100, Train Loss= 4.07, Training Accuracy= 0.00, Validation Loss= 3.33, Validation Accuracy:0.11\n",
            "Epoch 25200, Train Loss= 3.01, Training Accuracy= 0.00, Validation Loss= 3.41, Validation Accuracy:0.10\n",
            "Epoch 25300, Train Loss= 3.18, Training Accuracy= 0.00, Validation Loss= 3.35, Validation Accuracy:0.11\n",
            "Epoch 25400, Train Loss= 4.34, Training Accuracy= 0.00, Validation Loss= 3.37, Validation Accuracy:0.11\n",
            "Epoch 25500, Train Loss= 3.48, Training Accuracy= 0.00, Validation Loss= 3.40, Validation Accuracy:0.10\n",
            "Epoch 25600, Train Loss= 3.78, Training Accuracy= 0.00, Validation Loss= 3.40, Validation Accuracy:0.11\n",
            "Epoch 25700, Train Loss= 3.78, Training Accuracy= 0.00, Validation Loss= 3.48, Validation Accuracy:0.15\n",
            "Epoch 25800, Train Loss= 2.73, Training Accuracy= 0.00, Validation Loss= 3.44, Validation Accuracy:0.12\n",
            "Epoch 25900, Train Loss= 3.80, Training Accuracy= 0.25, Validation Loss= 3.45, Validation Accuracy:0.15\n",
            "Epoch 26000, Train Loss= 4.01, Training Accuracy= 0.00, Validation Loss= 3.35, Validation Accuracy:0.13\n",
            "Epoch 26100, Train Loss= 2.74, Training Accuracy= 0.50, Validation Loss= 3.35, Validation Accuracy:0.10\n",
            "Epoch 26200, Train Loss= 2.60, Training Accuracy= 0.00, Validation Loss= 3.32, Validation Accuracy:0.10\n",
            "Epoch 26300, Train Loss= 3.69, Training Accuracy= 0.25, Validation Loss= 3.35, Validation Accuracy:0.11\n",
            "Epoch 26400, Train Loss= 3.03, Training Accuracy= 0.00, Validation Loss= 3.41, Validation Accuracy:0.11\n",
            "Epoch 26500, Train Loss= 2.07, Training Accuracy= 0.25, Validation Loss= 3.37, Validation Accuracy:0.15\n",
            "Epoch 26600, Train Loss= 4.96, Training Accuracy= 0.00, Validation Loss= 3.37, Validation Accuracy:0.11\n",
            "Epoch 26700, Train Loss= 1.80, Training Accuracy= 0.25, Validation Loss= 3.31, Validation Accuracy:0.14\n",
            "Epoch 26800, Train Loss= 4.74, Training Accuracy= 0.00, Validation Loss= 3.35, Validation Accuracy:0.14\n",
            "Epoch 26900, Train Loss= 5.24, Training Accuracy= 0.00, Validation Loss= 3.39, Validation Accuracy:0.19\n",
            "Epoch 27000, Train Loss= 4.77, Training Accuracy= 0.00, Validation Loss= 3.44, Validation Accuracy:0.16\n",
            "Epoch 27100, Train Loss= 3.79, Training Accuracy= 0.00, Validation Loss= 3.50, Validation Accuracy:0.18\n",
            "Epoch 27200, Train Loss= 3.58, Training Accuracy= 0.25, Validation Loss= 3.44, Validation Accuracy:0.15\n",
            "Epoch 27300, Train Loss= 2.75, Training Accuracy= 0.25, Validation Loss= 3.43, Validation Accuracy:0.20\n",
            "Epoch 27400, Train Loss= 3.40, Training Accuracy= 0.00, Validation Loss= 3.41, Validation Accuracy:0.19\n",
            "Epoch 27500, Train Loss= 3.19, Training Accuracy= 0.25, Validation Loss= 3.46, Validation Accuracy:0.18\n",
            "Epoch 27600, Train Loss= 3.87, Training Accuracy= 0.00, Validation Loss= 3.43, Validation Accuracy:0.21\n",
            "Epoch 27700, Train Loss= 3.08, Training Accuracy= 0.25, Validation Loss= 3.40, Validation Accuracy:0.21\n",
            "Epoch 27800, Train Loss= 3.12, Training Accuracy= 0.50, Validation Loss= 3.44, Validation Accuracy:0.20\n",
            "Epoch 27900, Train Loss= 4.17, Training Accuracy= 0.25, Validation Loss= 3.38, Validation Accuracy:0.19\n",
            "Epoch 28000, Train Loss= 2.58, Training Accuracy= 0.25, Validation Loss= 3.41, Validation Accuracy:0.17\n",
            "Epoch 28100, Train Loss= 3.54, Training Accuracy= 0.25, Validation Loss= 3.47, Validation Accuracy:0.16\n",
            "Epoch 28200, Train Loss= 1.22, Training Accuracy= 0.25, Validation Loss= 3.48, Validation Accuracy:0.15\n",
            "Epoch 28300, Train Loss= 5.36, Training Accuracy= 0.00, Validation Loss= 3.56, Validation Accuracy:0.16\n",
            "Epoch 28400, Train Loss= 3.05, Training Accuracy= 0.00, Validation Loss= 3.58, Validation Accuracy:0.15\n",
            "Epoch 28500, Train Loss= 4.14, Training Accuracy= 0.25, Validation Loss= 3.55, Validation Accuracy:0.15\n",
            "Epoch 28600, Train Loss= 5.23, Training Accuracy= 0.25, Validation Loss= 3.61, Validation Accuracy:0.14\n",
            "Epoch 28700, Train Loss= 2.59, Training Accuracy= 0.25, Validation Loss= 3.59, Validation Accuracy:0.14\n",
            "Epoch 28800, Train Loss= 3.93, Training Accuracy= 0.00, Validation Loss= 3.52, Validation Accuracy:0.16\n",
            "Epoch 28900, Train Loss= 3.21, Training Accuracy= 0.50, Validation Loss= 3.48, Validation Accuracy:0.16\n",
            "Epoch 29000, Train Loss= 3.32, Training Accuracy= 0.00, Validation Loss= 3.56, Validation Accuracy:0.16\n",
            "Epoch 29100, Train Loss= 3.02, Training Accuracy= 0.25, Validation Loss= 3.52, Validation Accuracy:0.14\n",
            "Epoch 29200, Train Loss= 3.96, Training Accuracy= 0.25, Validation Loss= 3.59, Validation Accuracy:0.14\n",
            "Epoch 29300, Train Loss= 5.20, Training Accuracy= 0.00, Validation Loss= 3.59, Validation Accuracy:0.12\n",
            "Epoch 29400, Train Loss= 3.86, Training Accuracy= 0.00, Validation Loss= 3.57, Validation Accuracy:0.12\n",
            "Epoch 29500, Train Loss= 3.92, Training Accuracy= 0.00, Validation Loss= 3.60, Validation Accuracy:0.15\n",
            "Epoch 29600, Train Loss= 4.68, Training Accuracy= 0.00, Validation Loss= 3.50, Validation Accuracy:0.15\n",
            "Epoch 29700, Train Loss= 3.30, Training Accuracy= 0.25, Validation Loss= 3.44, Validation Accuracy:0.12\n",
            "Epoch 29800, Train Loss= 3.87, Training Accuracy= 0.00, Validation Loss= 3.45, Validation Accuracy:0.11\n",
            "Epoch 29900, Train Loss= 3.61, Training Accuracy= 0.00, Validation Loss= 3.43, Validation Accuracy:0.11\n",
            "Epoch 30000, Train Loss= 4.30, Training Accuracy= 0.25, Validation Loss= 3.46, Validation Accuracy:0.11\n",
            "Epoch 30100, Train Loss= 2.02, Training Accuracy= 0.25, Validation Loss= 3.51, Validation Accuracy:0.14\n",
            "Epoch 30200, Train Loss= 4.98, Training Accuracy= 0.00, Validation Loss= 3.45, Validation Accuracy:0.13\n",
            "Epoch 30300, Train Loss= 2.66, Training Accuracy= 0.00, Validation Loss= 3.50, Validation Accuracy:0.12\n",
            "Epoch 30400, Train Loss= 4.32, Training Accuracy= 0.00, Validation Loss= 3.52, Validation Accuracy:0.16\n",
            "Epoch 30500, Train Loss= 3.89, Training Accuracy= 0.00, Validation Loss= 3.48, Validation Accuracy:0.16\n",
            "Epoch 30600, Train Loss= 4.22, Training Accuracy= 0.25, Validation Loss= 3.45, Validation Accuracy:0.12\n",
            "Epoch 30700, Train Loss= 3.09, Training Accuracy= 0.00, Validation Loss= 3.44, Validation Accuracy:0.11\n",
            "Epoch 30800, Train Loss= 3.61, Training Accuracy= 0.25, Validation Loss= 3.46, Validation Accuracy:0.12\n",
            "Epoch 30900, Train Loss= 2.21, Training Accuracy= 0.00, Validation Loss= 3.43, Validation Accuracy:0.12\n",
            "Epoch 31000, Train Loss= 3.83, Training Accuracy= 0.00, Validation Loss= 3.48, Validation Accuracy:0.15\n",
            "Epoch 31100, Train Loss= 3.18, Training Accuracy= 0.00, Validation Loss= 3.49, Validation Accuracy:0.16\n",
            "Epoch 31200, Train Loss= 4.47, Training Accuracy= 0.00, Validation Loss= 3.49, Validation Accuracy:0.15\n",
            "Epoch 31300, Train Loss= 5.09, Training Accuracy= 0.00, Validation Loss= 3.44, Validation Accuracy:0.13\n",
            "Epoch 31400, Train Loss= 2.75, Training Accuracy= 0.25, Validation Loss= 3.48, Validation Accuracy:0.14\n",
            "Epoch 31500, Train Loss= 2.70, Training Accuracy= 0.00, Validation Loss= 3.43, Validation Accuracy:0.16\n",
            "Epoch 31600, Train Loss= 3.25, Training Accuracy= 0.00, Validation Loss= 3.41, Validation Accuracy:0.16\n",
            "Epoch 31700, Train Loss= 4.17, Training Accuracy= 0.00, Validation Loss= 3.48, Validation Accuracy:0.13\n",
            "Epoch 31800, Train Loss= 5.02, Training Accuracy= 0.25, Validation Loss= 3.43, Validation Accuracy:0.13\n",
            "Epoch 31900, Train Loss= 2.56, Training Accuracy= 0.50, Validation Loss= 3.50, Validation Accuracy:0.16\n",
            "Epoch 32000, Train Loss= 2.96, Training Accuracy= 0.25, Validation Loss= 3.51, Validation Accuracy:0.16\n",
            "Epoch 32100, Train Loss= 3.80, Training Accuracy= 0.00, Validation Loss= 3.51, Validation Accuracy:0.15\n",
            "Epoch 32200, Train Loss= 3.84, Training Accuracy= 0.00, Validation Loss= 3.54, Validation Accuracy:0.16\n",
            "Epoch 32300, Train Loss= 2.87, Training Accuracy= 0.50, Validation Loss= 3.50, Validation Accuracy:0.14\n",
            "Epoch 32400, Train Loss= 3.44, Training Accuracy= 0.00, Validation Loss= 3.50, Validation Accuracy:0.14\n",
            "Epoch 32500, Train Loss= 2.41, Training Accuracy= 0.25, Validation Loss= 3.47, Validation Accuracy:0.14\n",
            "Epoch 32600, Train Loss= 3.72, Training Accuracy= 0.25, Validation Loss= 3.55, Validation Accuracy:0.14\n",
            "Epoch 32700, Train Loss= 2.19, Training Accuracy= 0.25, Validation Loss= 3.53, Validation Accuracy:0.14\n",
            "Epoch 32800, Train Loss= 4.64, Training Accuracy= 0.00, Validation Loss= 3.50, Validation Accuracy:0.16\n",
            "Epoch 32900, Train Loss= 2.27, Training Accuracy= 0.50, Validation Loss= 3.49, Validation Accuracy:0.13\n",
            "Epoch 33000, Train Loss= 3.98, Training Accuracy= 0.25, Validation Loss= 3.58, Validation Accuracy:0.12\n",
            "Epoch 33100, Train Loss= 4.73, Training Accuracy= 0.00, Validation Loss= 3.55, Validation Accuracy:0.12\n",
            "Epoch 33200, Train Loss= 3.99, Training Accuracy= 0.00, Validation Loss= 3.53, Validation Accuracy:0.16\n",
            "Epoch 33300, Train Loss= 1.95, Training Accuracy= 0.25, Validation Loss= 3.53, Validation Accuracy:0.14\n",
            "Epoch 33400, Train Loss= 3.14, Training Accuracy= 0.25, Validation Loss= 3.59, Validation Accuracy:0.12\n",
            "Epoch 33500, Train Loss= 5.36, Training Accuracy= 0.00, Validation Loss= 3.56, Validation Accuracy:0.15\n",
            "Epoch 33600, Train Loss= 4.42, Training Accuracy= 0.25, Validation Loss= 3.61, Validation Accuracy:0.16\n",
            "Epoch 33700, Train Loss= 2.56, Training Accuracy= 0.25, Validation Loss= 3.60, Validation Accuracy:0.12\n",
            "Epoch 33800, Train Loss= 3.85, Training Accuracy= 0.00, Validation Loss= 3.63, Validation Accuracy:0.16\n",
            "Epoch 33900, Train Loss= 3.39, Training Accuracy= 0.00, Validation Loss= 3.61, Validation Accuracy:0.16\n",
            "Epoch 34000, Train Loss= 3.32, Training Accuracy= 0.25, Validation Loss= 3.63, Validation Accuracy:0.11\n",
            "Epoch 34100, Train Loss= 3.49, Training Accuracy= 0.00, Validation Loss= 3.47, Validation Accuracy:0.12\n",
            "Epoch 34200, Train Loss= 5.10, Training Accuracy= 0.00, Validation Loss= 3.59, Validation Accuracy:0.16\n",
            "Epoch 34300, Train Loss= 2.85, Training Accuracy= 0.00, Validation Loss= 3.58, Validation Accuracy:0.14\n",
            "Epoch 34400, Train Loss= 3.45, Training Accuracy= 0.00, Validation Loss= 3.59, Validation Accuracy:0.15\n",
            "Epoch 34500, Train Loss= 5.37, Training Accuracy= 0.00, Validation Loss= 3.63, Validation Accuracy:0.16\n",
            "Epoch 34600, Train Loss= 3.59, Training Accuracy= 0.00, Validation Loss= 3.56, Validation Accuracy:0.14\n",
            "Epoch 34700, Train Loss= 3.95, Training Accuracy= 0.25, Validation Loss= 3.59, Validation Accuracy:0.14\n",
            "Epoch 34800, Train Loss= 4.85, Training Accuracy= 0.00, Validation Loss= 3.60, Validation Accuracy:0.16\n",
            "Epoch 34900, Train Loss= 4.17, Training Accuracy= 0.00, Validation Loss= 3.53, Validation Accuracy:0.14\n",
            "Epoch 35000, Train Loss= 2.91, Training Accuracy= 0.25, Validation Loss= 3.60, Validation Accuracy:0.13\n",
            "Epoch 35100, Train Loss= 4.41, Training Accuracy= 0.00, Validation Loss= 3.54, Validation Accuracy:0.15\n",
            "Epoch 35200, Train Loss= 3.47, Training Accuracy= 0.00, Validation Loss= 3.59, Validation Accuracy:0.13\n",
            "Epoch 35300, Train Loss= 3.78, Training Accuracy= 0.00, Validation Loss= 3.56, Validation Accuracy:0.14\n",
            "Epoch 35400, Train Loss= 4.26, Training Accuracy= 0.25, Validation Loss= 3.51, Validation Accuracy:0.16\n",
            "Epoch 35500, Train Loss= 3.99, Training Accuracy= 0.00, Validation Loss= 3.45, Validation Accuracy:0.13\n",
            "Epoch 35600, Train Loss= 2.55, Training Accuracy= 0.25, Validation Loss= 3.50, Validation Accuracy:0.16\n",
            "Epoch 35700, Train Loss= 3.71, Training Accuracy= 0.00, Validation Loss= 3.46, Validation Accuracy:0.16\n",
            "Epoch 35800, Train Loss= 5.08, Training Accuracy= 0.00, Validation Loss= 3.47, Validation Accuracy:0.15\n",
            "Epoch 35900, Train Loss= 2.82, Training Accuracy= 0.25, Validation Loss= 3.41, Validation Accuracy:0.16\n",
            "Epoch 36000, Train Loss= 3.58, Training Accuracy= 0.00, Validation Loss= 3.51, Validation Accuracy:0.15\n",
            "Epoch 36100, Train Loss= 3.40, Training Accuracy= 0.50, Validation Loss= 3.54, Validation Accuracy:0.16\n",
            "Epoch 36200, Train Loss= 5.03, Training Accuracy= 0.00, Validation Loss= 3.47, Validation Accuracy:0.16\n",
            "Epoch 36300, Train Loss= 3.73, Training Accuracy= 0.25, Validation Loss= 3.48, Validation Accuracy:0.16\n",
            "Epoch 36400, Train Loss= 4.78, Training Accuracy= 0.00, Validation Loss= 3.52, Validation Accuracy:0.15\n",
            "Epoch 36500, Train Loss= 4.77, Training Accuracy= 0.00, Validation Loss= 3.61, Validation Accuracy:0.10\n",
            "Epoch 36600, Train Loss= 4.45, Training Accuracy= 0.00, Validation Loss= 3.63, Validation Accuracy:0.10\n",
            "Epoch 36700, Train Loss= 4.47, Training Accuracy= 0.00, Validation Loss= 3.70, Validation Accuracy:0.11\n",
            "Epoch 36800, Train Loss= 2.44, Training Accuracy= 0.00, Validation Loss= 3.62, Validation Accuracy:0.11\n",
            "Epoch 36900, Train Loss= 5.37, Training Accuracy= 0.00, Validation Loss= 3.61, Validation Accuracy:0.10\n",
            "Epoch 37000, Train Loss= 3.71, Training Accuracy= 0.00, Validation Loss= 3.56, Validation Accuracy:0.10\n",
            "Epoch 37100, Train Loss= 3.81, Training Accuracy= 0.25, Validation Loss= 3.57, Validation Accuracy:0.12\n",
            "Epoch 37200, Train Loss= 3.33, Training Accuracy= 0.00, Validation Loss= 3.40, Validation Accuracy:0.12\n",
            "Epoch 37300, Train Loss= 2.68, Training Accuracy= 0.00, Validation Loss= 3.40, Validation Accuracy:0.11\n",
            "Epoch 37400, Train Loss= 2.31, Training Accuracy= 0.25, Validation Loss= 3.46, Validation Accuracy:0.13\n",
            "Epoch 37500, Train Loss= 3.12, Training Accuracy= 0.00, Validation Loss= 3.51, Validation Accuracy:0.16\n",
            "Epoch 37600, Train Loss= 3.72, Training Accuracy= 0.00, Validation Loss= 3.55, Validation Accuracy:0.15\n",
            "Epoch 37700, Train Loss= 2.60, Training Accuracy= 0.50, Validation Loss= 3.64, Validation Accuracy:0.15\n",
            "Epoch 37800, Train Loss= 2.44, Training Accuracy= 0.50, Validation Loss= 3.63, Validation Accuracy:0.10\n",
            "Epoch 37900, Train Loss= 5.09, Training Accuracy= 0.00, Validation Loss= 3.49, Validation Accuracy:0.14\n",
            "Epoch 38000, Train Loss= 2.91, Training Accuracy= 0.50, Validation Loss= 3.47, Validation Accuracy:0.16\n",
            "Epoch 38100, Train Loss= 3.50, Training Accuracy= 0.25, Validation Loss= 3.39, Validation Accuracy:0.15\n",
            "Epoch 38200, Train Loss= 4.07, Training Accuracy= 0.00, Validation Loss= 3.36, Validation Accuracy:0.14\n",
            "Epoch 38300, Train Loss= 3.01, Training Accuracy= 0.00, Validation Loss= 3.36, Validation Accuracy:0.16\n",
            "Epoch 38400, Train Loss= 2.92, Training Accuracy= 0.25, Validation Loss= 3.38, Validation Accuracy:0.15\n",
            "Epoch 38500, Train Loss= 3.30, Training Accuracy= 0.00, Validation Loss= 3.38, Validation Accuracy:0.15\n",
            "Epoch 38600, Train Loss= 1.55, Training Accuracy= 0.50, Validation Loss= 3.40, Validation Accuracy:0.16\n",
            "Epoch 38700, Train Loss= 3.01, Training Accuracy= 0.00, Validation Loss= 3.44, Validation Accuracy:0.14\n",
            "Epoch 38800, Train Loss= 4.25, Training Accuracy= 0.25, Validation Loss= 3.47, Validation Accuracy:0.16\n",
            "Epoch 38900, Train Loss= 4.61, Training Accuracy= 0.00, Validation Loss= 3.44, Validation Accuracy:0.16\n",
            "Epoch 39000, Train Loss= 3.53, Training Accuracy= 0.25, Validation Loss= 3.47, Validation Accuracy:0.16\n",
            "Epoch 39100, Train Loss= 3.30, Training Accuracy= 0.00, Validation Loss= 3.54, Validation Accuracy:0.12\n",
            "Epoch 39200, Train Loss= 4.56, Training Accuracy= 0.00, Validation Loss= 3.63, Validation Accuracy:0.15\n",
            "Epoch 39300, Train Loss= 2.97, Training Accuracy= 0.25, Validation Loss= 3.63, Validation Accuracy:0.16\n",
            "Epoch 39400, Train Loss= 5.14, Training Accuracy= 0.00, Validation Loss= 3.62, Validation Accuracy:0.16\n",
            "Epoch 39500, Train Loss= 4.83, Training Accuracy= 0.00, Validation Loss= 3.66, Validation Accuracy:0.15\n",
            "Epoch 39600, Train Loss= 3.40, Training Accuracy= 0.00, Validation Loss= 3.62, Validation Accuracy:0.14\n",
            "Epoch 39700, Train Loss= 4.30, Training Accuracy= 0.00, Validation Loss= 3.60, Validation Accuracy:0.16\n",
            "Epoch 39800, Train Loss= 5.46, Training Accuracy= 0.25, Validation Loss= 3.66, Validation Accuracy:0.11\n",
            "Epoch 39900, Train Loss= 3.55, Training Accuracy= 0.25, Validation Loss= 3.66, Validation Accuracy:0.10\n",
            "Epoch 40000, Train Loss= 6.29, Training Accuracy= 0.00, Validation Loss= 3.69, Validation Accuracy:0.10\n",
            "Epoch 40100, Train Loss= 3.48, Training Accuracy= 0.00, Validation Loss= 3.79, Validation Accuracy:0.10\n",
            "Epoch 40200, Train Loss= 4.43, Training Accuracy= 0.00, Validation Loss= 3.83, Validation Accuracy:0.10\n",
            "Epoch 40300, Train Loss= 5.23, Training Accuracy= 0.00, Validation Loss= 3.70, Validation Accuracy:0.11\n",
            "Epoch 40400, Train Loss= 5.28, Training Accuracy= 0.00, Validation Loss= 3.72, Validation Accuracy:0.12\n",
            "Epoch 40500, Train Loss= 3.89, Training Accuracy= 0.00, Validation Loss= 3.67, Validation Accuracy:0.14\n",
            "Epoch 40600, Train Loss= 4.44, Training Accuracy= 0.00, Validation Loss= 3.63, Validation Accuracy:0.16\n",
            "Epoch 40700, Train Loss= 1.97, Training Accuracy= 0.00, Validation Loss= 3.68, Validation Accuracy:0.12\n",
            "Epoch 40800, Train Loss= 3.58, Training Accuracy= 0.00, Validation Loss= 3.54, Validation Accuracy:0.14\n",
            "Epoch 40900, Train Loss= 2.33, Training Accuracy= 0.50, Validation Loss= 3.54, Validation Accuracy:0.15\n",
            "Epoch 41000, Train Loss= 4.06, Training Accuracy= 0.00, Validation Loss= 3.52, Validation Accuracy:0.12\n",
            "Epoch 41100, Train Loss= 3.38, Training Accuracy= 0.25, Validation Loss= 3.49, Validation Accuracy:0.14\n",
            "Epoch 41200, Train Loss= 4.10, Training Accuracy= 0.25, Validation Loss= 3.53, Validation Accuracy:0.13\n",
            "Epoch 41300, Train Loss= 4.45, Training Accuracy= 0.00, Validation Loss= 3.42, Validation Accuracy:0.16\n",
            "Epoch 41400, Train Loss= 2.28, Training Accuracy= 0.25, Validation Loss= 3.51, Validation Accuracy:0.16\n",
            "Epoch 41500, Train Loss= 3.92, Training Accuracy= 0.00, Validation Loss= 3.47, Validation Accuracy:0.15\n",
            "Epoch 41600, Train Loss= 3.88, Training Accuracy= 0.00, Validation Loss= 3.44, Validation Accuracy:0.15\n",
            "Epoch 41700, Train Loss= 4.40, Training Accuracy= 0.00, Validation Loss= 3.57, Validation Accuracy:0.16\n",
            "Epoch 41800, Train Loss= 5.77, Training Accuracy= 0.00, Validation Loss= 3.57, Validation Accuracy:0.16\n",
            "Epoch 41900, Train Loss= 4.48, Training Accuracy= 0.25, Validation Loss= 3.64, Validation Accuracy:0.13\n",
            "Epoch 42000, Train Loss= 3.64, Training Accuracy= 0.50, Validation Loss= 3.62, Validation Accuracy:0.13\n",
            "Epoch 42100, Train Loss= 4.92, Training Accuracy= 0.00, Validation Loss= 3.68, Validation Accuracy:0.11\n",
            "Epoch 42200, Train Loss= 5.13, Training Accuracy= 0.00, Validation Loss= 3.67, Validation Accuracy:0.10\n",
            "Epoch 42300, Train Loss= 3.15, Training Accuracy= 0.25, Validation Loss= 3.64, Validation Accuracy:0.11\n",
            "Epoch 42400, Train Loss= 2.33, Training Accuracy= 0.00, Validation Loss= 3.76, Validation Accuracy:0.11\n",
            "Epoch 42500, Train Loss= 4.05, Training Accuracy= 0.00, Validation Loss= 3.73, Validation Accuracy:0.11\n",
            "Epoch 42600, Train Loss= 5.64, Training Accuracy= 0.00, Validation Loss= 3.74, Validation Accuracy:0.12\n",
            "Epoch 42700, Train Loss= 3.25, Training Accuracy= 0.25, Validation Loss= 3.77, Validation Accuracy:0.11\n",
            "Epoch 42800, Train Loss= 2.70, Training Accuracy= 0.25, Validation Loss= 3.76, Validation Accuracy:0.10\n",
            "Epoch 42900, Train Loss= 6.59, Training Accuracy= 0.00, Validation Loss= 3.78, Validation Accuracy:0.10\n",
            "Epoch 43000, Train Loss= 4.33, Training Accuracy= 0.00, Validation Loss= 3.80, Validation Accuracy:0.10\n",
            "Epoch 43100, Train Loss= 4.75, Training Accuracy= 0.00, Validation Loss= 3.75, Validation Accuracy:0.10\n",
            "Epoch 43200, Train Loss= 3.97, Training Accuracy= 0.25, Validation Loss= 3.76, Validation Accuracy:0.10\n",
            "Epoch 43300, Train Loss= 4.81, Training Accuracy= 0.00, Validation Loss= 3.76, Validation Accuracy:0.10\n",
            "Epoch 43400, Train Loss= 3.06, Training Accuracy= 0.25, Validation Loss= 3.77, Validation Accuracy:0.10\n",
            "Epoch 43500, Train Loss= 4.56, Training Accuracy= 0.00, Validation Loss= 3.71, Validation Accuracy:0.10\n",
            "Epoch 43600, Train Loss= 5.01, Training Accuracy= 0.00, Validation Loss= 3.62, Validation Accuracy:0.10\n",
            "Epoch 43700, Train Loss= 2.99, Training Accuracy= 0.25, Validation Loss= 3.63, Validation Accuracy:0.10\n",
            "Epoch 43800, Train Loss= 1.72, Training Accuracy= 0.25, Validation Loss= 3.61, Validation Accuracy:0.10\n",
            "Epoch 43900, Train Loss= 3.48, Training Accuracy= 0.00, Validation Loss= 3.68, Validation Accuracy:0.10\n",
            "Epoch 44000, Train Loss= 3.66, Training Accuracy= 0.00, Validation Loss= 3.74, Validation Accuracy:0.10\n",
            "Epoch 44100, Train Loss= 4.42, Training Accuracy= 0.00, Validation Loss= 3.71, Validation Accuracy:0.10\n",
            "Epoch 44200, Train Loss= 4.38, Training Accuracy= 0.00, Validation Loss= 3.67, Validation Accuracy:0.10\n",
            "Epoch 44300, Train Loss= 3.98, Training Accuracy= 0.00, Validation Loss= 3.62, Validation Accuracy:0.11\n",
            "Epoch 44400, Train Loss= 3.23, Training Accuracy= 0.25, Validation Loss= 3.70, Validation Accuracy:0.12\n",
            "Epoch 44500, Train Loss= 4.46, Training Accuracy= 0.00, Validation Loss= 3.69, Validation Accuracy:0.11\n",
            "Epoch 44600, Train Loss= 5.84, Training Accuracy= 0.00, Validation Loss= 3.63, Validation Accuracy:0.13\n",
            "Epoch 44700, Train Loss= 5.62, Training Accuracy= 0.00, Validation Loss= 3.62, Validation Accuracy:0.10\n",
            "Epoch 44800, Train Loss= 2.53, Training Accuracy= 0.25, Validation Loss= 3.64, Validation Accuracy:0.10\n",
            "Epoch 44900, Train Loss= 3.68, Training Accuracy= 0.00, Validation Loss= 3.68, Validation Accuracy:0.10\n",
            "Epoch 45000, Train Loss= 4.36, Training Accuracy= 0.00, Validation Loss= 3.72, Validation Accuracy:0.15\n",
            "Epoch 45100, Train Loss= 3.63, Training Accuracy= 0.00, Validation Loss= 3.60, Validation Accuracy:0.12\n",
            "Epoch 45200, Train Loss= 1.23, Training Accuracy= 0.25, Validation Loss= 3.55, Validation Accuracy:0.11\n",
            "Epoch 45300, Train Loss= 4.37, Training Accuracy= 0.00, Validation Loss= 3.58, Validation Accuracy:0.10\n",
            "Epoch 45400, Train Loss= 4.66, Training Accuracy= 0.00, Validation Loss= 3.61, Validation Accuracy:0.15\n",
            "Epoch 45500, Train Loss= 3.31, Training Accuracy= 0.00, Validation Loss= 3.72, Validation Accuracy:0.15\n",
            "Epoch 45600, Train Loss= 4.68, Training Accuracy= 0.00, Validation Loss= 3.74, Validation Accuracy:0.15\n",
            "Epoch 45700, Train Loss= 4.03, Training Accuracy= 0.00, Validation Loss= 3.75, Validation Accuracy:0.14\n",
            "Epoch 45800, Train Loss= 1.44, Training Accuracy= 0.50, Validation Loss= 3.68, Validation Accuracy:0.13\n",
            "Epoch 45900, Train Loss= 4.14, Training Accuracy= 0.25, Validation Loss= 3.70, Validation Accuracy:0.10\n",
            "Epoch 46000, Train Loss= 6.17, Training Accuracy= 0.00, Validation Loss= 3.68, Validation Accuracy:0.11\n",
            "Epoch 46100, Train Loss= 2.92, Training Accuracy= 0.00, Validation Loss= 3.71, Validation Accuracy:0.10\n",
            "Epoch 46200, Train Loss= 2.16, Training Accuracy= 0.50, Validation Loss= 3.65, Validation Accuracy:0.11\n",
            "Epoch 46300, Train Loss= 4.47, Training Accuracy= 0.00, Validation Loss= 3.53, Validation Accuracy:0.16\n",
            "Epoch 46400, Train Loss= 5.40, Training Accuracy= 0.25, Validation Loss= 3.49, Validation Accuracy:0.16\n",
            "Epoch 46500, Train Loss= 3.82, Training Accuracy= 0.00, Validation Loss= 3.52, Validation Accuracy:0.15\n",
            "Epoch 46600, Train Loss= 2.15, Training Accuracy= 0.25, Validation Loss= 3.48, Validation Accuracy:0.16\n",
            "Epoch 46700, Train Loss= 3.09, Training Accuracy= 0.00, Validation Loss= 3.55, Validation Accuracy:0.16\n",
            "Epoch 46800, Train Loss= 3.26, Training Accuracy= 0.25, Validation Loss= 3.41, Validation Accuracy:0.15\n",
            "Epoch 46900, Train Loss= 3.76, Training Accuracy= 0.00, Validation Loss= 3.44, Validation Accuracy:0.15\n",
            "Epoch 47000, Train Loss= 2.91, Training Accuracy= 0.00, Validation Loss= 3.41, Validation Accuracy:0.14\n",
            "Epoch 47100, Train Loss= 4.13, Training Accuracy= 0.25, Validation Loss= 3.43, Validation Accuracy:0.13\n",
            "Epoch 47200, Train Loss= 3.37, Training Accuracy= 0.25, Validation Loss= 3.47, Validation Accuracy:0.10\n",
            "Epoch 47300, Train Loss= 5.20, Training Accuracy= 0.00, Validation Loss= 3.52, Validation Accuracy:0.16\n",
            "Epoch 47400, Train Loss= 2.85, Training Accuracy= 0.25, Validation Loss= 3.56, Validation Accuracy:0.13\n",
            "Epoch 47500, Train Loss= 4.02, Training Accuracy= 0.00, Validation Loss= 3.56, Validation Accuracy:0.16\n",
            "Epoch 47600, Train Loss= 5.97, Training Accuracy= 0.00, Validation Loss= 3.57, Validation Accuracy:0.11\n",
            "Epoch 47700, Train Loss= 5.02, Training Accuracy= 0.00, Validation Loss= 3.64, Validation Accuracy:0.11\n",
            "Epoch 47800, Train Loss= 3.31, Training Accuracy= 0.00, Validation Loss= 3.62, Validation Accuracy:0.11\n",
            "Epoch 47900, Train Loss= 2.83, Training Accuracy= 0.25, Validation Loss= 3.59, Validation Accuracy:0.10\n",
            "Epoch 48000, Train Loss= 4.28, Training Accuracy= 0.00, Validation Loss= 3.63, Validation Accuracy:0.11\n",
            "Epoch 48100, Train Loss= 3.48, Training Accuracy= 0.25, Validation Loss= 3.69, Validation Accuracy:0.11\n",
            "Epoch 48200, Train Loss= 2.94, Training Accuracy= 0.25, Validation Loss= 3.75, Validation Accuracy:0.16\n",
            "Epoch 48300, Train Loss= 1.70, Training Accuracy= 0.25, Validation Loss= 3.73, Validation Accuracy:0.16\n",
            "Epoch 48400, Train Loss= 3.31, Training Accuracy= 0.25, Validation Loss= 3.67, Validation Accuracy:0.16\n",
            "Epoch 48500, Train Loss= 3.91, Training Accuracy= 0.00, Validation Loss= 3.70, Validation Accuracy:0.14\n",
            "Epoch 48600, Train Loss= 6.36, Training Accuracy= 0.00, Validation Loss= 3.75, Validation Accuracy:0.10\n",
            "Epoch 48700, Train Loss= 5.77, Training Accuracy= 0.00, Validation Loss= 3.75, Validation Accuracy:0.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-cec70519bc92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# Evaluate the test accuracy with no dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mloss_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Train Loss= \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Training Accuracy= \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", Validation Loss= \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m\", Validation Accuracy:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4pzLU_9ZS9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(25, 10))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Loss Curve\")\n",
        "plt.plot(train_loss, 'r', label='Training Loss')\n",
        "plt.plot(validation_loss,  'c', label='Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.plot(train_acc, 'r', label='Training Acc')\n",
        "plt.plot(validation_acc, 'c', label='Validation Acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()     "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}