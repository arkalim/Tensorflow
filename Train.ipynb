{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkalim/Tensorflow/blob/master/Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEJIVjAwtFPs",
        "colab_type": "text"
      },
      "source": [
        "# Train DeepLab V3\n",
        "\n",
        "## Clone the repository for necessary helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFaSVkRdQwy4",
        "colab_type": "code",
        "outputId": "66a4da4d-55b3-4961-eee0-757057651a31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import os\n",
        "\n",
        "!git clone https://github.com/sthalles/deeplab_v3.git\n",
        "os.listdir('/content/deeplab_v3')\n",
        "os.chdir('deeplab_v3')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deeplab_v3'...\n",
            "remote: Enumerating objects: 267, done.\u001b[K\n",
            "Receiving objects:   0% (1/267)   \rReceiving objects:   1% (3/267)   \rReceiving objects:   2% (6/267)   \rReceiving objects:   3% (9/267)   \rReceiving objects:   4% (11/267)   \rReceiving objects:   5% (14/267)   \rReceiving objects:   6% (17/267)   \rReceiving objects:   7% (19/267)   \rReceiving objects:   8% (22/267)   \rReceiving objects:   9% (25/267)   \rReceiving objects:  10% (27/267)   \rReceiving objects:  11% (30/267)   \rReceiving objects:  12% (33/267)   \rReceiving objects:  13% (35/267)   \rReceiving objects:  14% (38/267)   \rReceiving objects:  15% (41/267)   \rReceiving objects:  16% (43/267)   \rReceiving objects:  17% (46/267)   \rReceiving objects:  18% (49/267)   \rReceiving objects:  19% (51/267)   \rReceiving objects:  20% (54/267)   \rReceiving objects:  21% (57/267)   \rReceiving objects:  22% (59/267)   \rReceiving objects:  23% (62/267)   \rReceiving objects:  24% (65/267)   \rReceiving objects:  25% (67/267)   \rReceiving objects:  26% (70/267)   \rReceiving objects:  27% (73/267)   \rReceiving objects:  28% (75/267)   \rReceiving objects:  29% (78/267)   \rReceiving objects:  30% (81/267)   \rReceiving objects:  31% (83/267)   \rReceiving objects:  32% (86/267)   \rReceiving objects:  33% (89/267)   \rReceiving objects:  34% (91/267)   \rReceiving objects:  35% (94/267)   \rReceiving objects:  36% (97/267)   \rReceiving objects:  37% (99/267)   \rReceiving objects:  38% (102/267)   \rReceiving objects:  39% (105/267)   \rReceiving objects:  40% (107/267)   \rReceiving objects:  41% (110/267)   \rReceiving objects:  42% (113/267)   \rReceiving objects:  43% (115/267)   \rReceiving objects:  44% (118/267)   \rremote: Total 267 (delta 0), reused 0 (delta 0), pack-reused 267\u001b[K\n",
            "Receiving objects:  45% (121/267)   \rReceiving objects:  46% (123/267)   \rReceiving objects:  47% (126/267)   \rReceiving objects:  48% (129/267)   \rReceiving objects:  49% (131/267)   \rReceiving objects:  50% (134/267)   \rReceiving objects:  51% (137/267)   \rReceiving objects:  52% (139/267)   \rReceiving objects:  53% (142/267)   \rReceiving objects:  54% (145/267)   \rReceiving objects:  55% (147/267)   \rReceiving objects:  56% (150/267)   \rReceiving objects:  57% (153/267)   \rReceiving objects:  58% (155/267)   \rReceiving objects:  59% (158/267)   \rReceiving objects:  60% (161/267)   \rReceiving objects:  61% (163/267)   \rReceiving objects:  62% (166/267)   \rReceiving objects:  63% (169/267)   \rReceiving objects:  64% (171/267)   \rReceiving objects:  65% (174/267)   \rReceiving objects:  66% (177/267)   \rReceiving objects:  67% (179/267)   \rReceiving objects:  68% (182/267)   \rReceiving objects:  69% (185/267)   \rReceiving objects:  70% (187/267)   \rReceiving objects:  71% (190/267)   \rReceiving objects:  72% (193/267)   \rReceiving objects:  73% (195/267)   \rReceiving objects:  74% (198/267)   \rReceiving objects:  75% (201/267)   \rReceiving objects:  76% (203/267)   \rReceiving objects:  77% (206/267)   \rReceiving objects:  78% (209/267)   \rReceiving objects:  79% (211/267)   \rReceiving objects:  80% (214/267)   \rReceiving objects:  81% (217/267)   \rReceiving objects:  82% (219/267)   \rReceiving objects:  83% (222/267)   \rReceiving objects:  84% (225/267)   \rReceiving objects:  85% (227/267)   \rReceiving objects:  86% (230/267)   \rReceiving objects:  87% (233/267)   \rReceiving objects:  88% (235/267)   \rReceiving objects:  89% (238/267)   \rReceiving objects:  90% (241/267)   \rReceiving objects:  91% (243/267)   \rReceiving objects:  92% (246/267)   \rReceiving objects:  93% (249/267)   \rReceiving objects:  94% (251/267)   \rReceiving objects:  95% (254/267)   \rReceiving objects:  96% (257/267)   \rReceiving objects:  97% (259/267)   \rReceiving objects:  98% (262/267)   \rReceiving objects:  99% (265/267)   \rReceiving objects: 100% (267/267)   \rReceiving objects: 100% (267/267), 571.29 KiB | 10.78 MiB/s, done.\n",
            "Resolving deltas:   0% (0/136)   \rResolving deltas:   1% (2/136)   \rResolving deltas:   5% (8/136)   \rResolving deltas:   7% (10/136)   \rResolving deltas:   8% (11/136)   \rResolving deltas:   9% (13/136)   \rResolving deltas:  14% (20/136)   \rResolving deltas:  16% (22/136)   \rResolving deltas:  18% (25/136)   \rResolving deltas:  19% (27/136)   \rResolving deltas:  22% (31/136)   \rResolving deltas:  24% (33/136)   \rResolving deltas:  27% (38/136)   \rResolving deltas:  55% (76/136)   \rResolving deltas:  57% (78/136)   \rResolving deltas:  63% (87/136)   \rResolving deltas:  67% (92/136)   \rResolving deltas:  70% (96/136)   \rResolving deltas:  77% (105/136)   \rResolving deltas:  86% (118/136)   \rResolving deltas:  88% (121/136)   \rResolving deltas:  92% (126/136)   \rResolving deltas:  93% (127/136)   \rResolving deltas:  94% (129/136)   \rResolving deltas:  98% (134/136)   \rResolving deltas:  99% (135/136)   \rResolving deltas: 100% (136/136)   \rResolving deltas: 100% (136/136), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D67uBlW001It",
        "colab_type": "code",
        "outputId": "46461be9-3125-4061-831a-75fc0ebb7c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "slim = tf.contrib.slim\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import network\n",
        "from preprocessing.read_data import download_resnet_checkpoint_if_necessary, tf_record_parser, \\\n",
        "    rescale_image_and_annotation_by_factor, scale_image_with_crop_padding, \\\n",
        "    random_flip_image_and_annotation, distort_randomly_image_color\n",
        "from preprocessing import training"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0619 04:50:20.745241 139633178437504 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D32irFxY027J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_norm_epsilon = 1e-5            # batch norm epsilon for batch normalization\n",
        "batch_norm_decay = 0.9997            # batch norm decay for batch normalization\n",
        "number_of_classes = 21               # number of classes to predict \n",
        "l2_regularizer = 0.0001              # l2 regularization parameter\n",
        "multi_grid = [1,2,4]                 # Spatial Pyramid Pooling rates\n",
        "output_stride = 16                   # Output Stride\n",
        "crop_size = 513                      # Image size to feed in the network\n",
        "resnet_model = 'resnet_v2_50'        # Resnet Model [choices: \"resnet_v2_50\", \"resnet_v2_101\", \"resnet_v2_152\", \"resnet_v2_200\"]\n",
        "batch_size = 8                       # Batch size \n",
        "img_shape = (513,513,3)\n",
        "\n",
        "num_train_examples = 8498\n",
        "num_valid_examples = 2857\n",
        "\n",
        "classes = [\"background\",\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"potted plant\", \"sheep\", \"sofa\", \"train\", \"tv monitor\", \"Unknown\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vt01DP10Bdn",
        "colab_type": "code",
        "outputId": "fd11e931-5f9e-44f8-ed92-91acd6a408c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.listdir('/content/tfrecords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train.tfrecords', 'validation.tfrecords']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3YN9PYg1k-D",
        "colab_type": "text"
      },
      "source": [
        "# Prepare data pipeline from tf record"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFdeJw2k1g0_",
        "colab_type": "code",
        "outputId": "3fa1a40e-c065-4407-bd8a-b84ed44fed40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "LOG_FOLDER = '/content/checkpoints'\n",
        "TRAIN_DATASET_DIR=\"/content/tfrecords\"\n",
        "TRAIN_FILE = 'train.tfrecords'\n",
        "VALIDATION_FILE = 'validation.tfrecords'\n",
        "\n",
        "# Train Dataset\n",
        "training_filenames = [os.path.join(TRAIN_DATASET_DIR,TRAIN_FILE)]\n",
        "training_dataset = tf.data.TFRecordDataset(training_filenames)\n",
        "training_dataset = training_dataset.map(tf_record_parser)\n",
        "training_dataset = training_dataset.map(rescale_image_and_annotation_by_factor)\n",
        "training_dataset = training_dataset.map(distort_randomly_image_color)\n",
        "training_dataset = training_dataset.map(lambda image, annotation, image_shape: scale_image_with_crop_padding(image, annotation, image_shape, crop_size))\n",
        "training_dataset = training_dataset.map(random_flip_image_and_annotation)  # Parse the record into tensors.\n",
        "training_dataset = training_dataset.repeat()  # number of epochs\n",
        "training_dataset = training_dataset.shuffle(buffer_size=500)\n",
        "training_dataset = training_dataset.batch(batch_size)\n",
        "\n",
        "# Validation Dataset\n",
        "validation_filenames = [os.path.join(TRAIN_DATASET_DIR,VALIDATION_FILE)]\n",
        "validation_dataset = tf.data.TFRecordDataset(validation_filenames)\n",
        "validation_dataset = validation_dataset.map(tf_record_parser)  # Parse the record into tensors.\n",
        "validation_dataset = validation_dataset.map(lambda image, annotation, image_shape: scale_image_with_crop_padding(image, annotation, image_shape, crop_size))\n",
        "validation_dataset = validation_dataset.shuffle(buffer_size=100)\n",
        "validation_dataset = validation_dataset.batch(batch_size)\n",
        "\n",
        "# A feedable iterator is defined by a handle placeholder and its structure.\n",
        "handle = tf.placeholder(tf.string, shape=[])\n",
        "\n",
        "iterator = tf.data.Iterator.from_string_handle(handle, training_dataset.output_types, training_dataset.output_shapes)\n",
        "batch_images_tf, batch_labels_tf, _ = iterator.get_next()\n",
        "\n",
        "# You can use feedable iterators with a variety of different kinds of iterator\n",
        "# (such as one-shot and initializable iterators).\n",
        "train_iterator = training_dataset.make_initializable_iterator()\n",
        "valid_iterator = validation_dataset.make_initializable_iterator()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0619 04:50:20.906049 139633178437504 deprecation_wrapper.py:119] From /content/deeplab_v3/preprocessing/read_data.py:115: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0619 04:50:20.907540 139633178437504 deprecation_wrapper.py:119] From /content/deeplab_v3/preprocessing/read_data.py:121: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0619 04:50:20.938275 139633178437504 deprecation.py:323] From /content/deeplab_v3/preprocessing/read_data.py:132: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0619 04:50:20.940353 139633178437504 deprecation.py:323] From /content/deeplab_v3/preprocessing/read_data.py:134: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0619 04:50:20.967399 139633178437504 deprecation_wrapper.py:119] From /content/deeplab_v3/preprocessing/read_data.py:56: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0619 04:50:20.981494 139633178437504 deprecation_wrapper.py:119] From /content/deeplab_v3/preprocessing/read_data.py:62: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0619 04:50:21.160007 139633178437504 deprecation_wrapper.py:119] From /content/deeplab_v3/preprocessing/read_data.py:98: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
            "\n",
            "W0619 04:50:23.126173 139633178437504 deprecation.py:323] From <ipython-input-5-b58cb132a311>:29: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
            "W0619 04:50:23.127605 139633178437504 deprecation.py:323] From <ipython-input-5-b58cb132a311>:29: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
            "W0619 04:50:23.138788 139633178437504 deprecation.py:323] From <ipython-input-5-b58cb132a311>:34: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5aK8RD18r0N",
        "colab_type": "text"
      },
      "source": [
        "# Create a temporary dataset for visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJb6sgrG8mAS",
        "colab_type": "code",
        "outputId": "0074c6a0-fcee-4bb5-f1d4-6dc9af73f3bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Temporary Dataset\n",
        "validation_filenames = [os.path.join(TRAIN_DATASET_DIR,VALIDATION_FILE)]\n",
        "temp_dataset = tf.data.TFRecordDataset(validation_filenames)\n",
        "temp_dataset = temp_dataset.map(tf_record_parser)\n",
        "temp_dataset = temp_dataset.map(lambda image, annotation, image_shape: scale_image_with_crop_padding(image, annotation, image_shape, crop_size)) \n",
        "temp_dataset = temp_dataset.shuffle(buffer_size=500)\n",
        "temp_dataset = temp_dataset.batch(8)\n",
        "\n",
        "temp_iterator = temp_dataset.make_one_shot_iterator()\n",
        "temp_images_tf, temp_labels_tf, _ = temp_iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0619 04:50:23.505025 139633178437504 deprecation.py:323] From <ipython-input-6-431d020cd9c4>:8: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GorxgVNMC8-t",
        "colab_type": "text"
      },
      "source": [
        "# Visualise Train Augmentation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DycD6627Pnp",
        "colab_type": "code",
        "outputId": "1780352b-724e-4610-d2f1-7e701071aca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    \n",
        "    image, annotation = sess.run([temp_images_tf,temp_labels_tf])\n",
        "    \n",
        "    print('Image Shape: {}'.format(np.shape(image)))\n",
        "    print('Annotation Shape: {}'.format(np.shape(annotation)))\n",
        "\n",
        "    plt.figure(figsize = (40,10))\n",
        "    \n",
        "    for i in range(8):\n",
        "        plt.subplot(2,4,i+1)\n",
        "        plt.imshow(annotation[i])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Shape: (8, 513, 513, 3)\n",
            "Annotation Shape: (8, 513, 513)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAB/UAAAJCCAYAAAAx2pQCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHvz1/l+KAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 2880x720 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3fCx_1jAbHh",
        "colab_type": "text"
      },
      "source": [
        "# Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dQVKr1o8WAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "slim = tf.contrib.slim\n",
        "from resnet import resnet_v2, resnet_utils\n",
        "\n",
        "# ImageNet mean statistics\n",
        "_R_MEAN = 123.68\n",
        "_G_MEAN = 116.78\n",
        "_B_MEAN = 103.94\n",
        "\n",
        "@slim.add_arg_scope\n",
        "def atrous_spatial_pyramid_pooling(net, scope, depth=256, reuse=None):\n",
        "    \"\"\"\n",
        "    ASPP consists of (a) one 1×1 convolution and three 3×3 convolutions with rates = (6, 12, 18) when output stride = 16\n",
        "    (all with 256 filters and batch normalization), and (b) the image-level features as described in https://arxiv.org/abs/1706.05587\n",
        "    :param net: tensor of shape [BATCH_SIZE, WIDTH, HEIGHT, DEPTH]\n",
        "    :param scope: scope name of the aspp layer\n",
        "    :return: network layer with aspp applyed to it.\n",
        "    \"\"\"\n",
        "\n",
        "    with tf.variable_scope(scope, reuse=reuse):\n",
        "        feature_map_size = tf.shape(net)\n",
        "\n",
        "        # apply global average pooling\n",
        "        image_level_features = tf.reduce_mean(net, [1, 2], name='image_level_global_pool', keepdims=True)\n",
        "        \n",
        "        image_level_features = slim.conv2d(image_level_features, depth, [1, 1], scope=\"image_level_conv_1x1\", activation_fn=None)\n",
        "        \n",
        "        image_level_features = tf.image.resize_bilinear(image_level_features, (feature_map_size[1], feature_map_size[2]))\n",
        "\n",
        "        at_pool1x1 = slim.conv2d(net, depth, [1, 1], scope=\"conv_1x1_0\", activation_fn=None)\n",
        "\n",
        "        at_pool3x3_1 = slim.conv2d(net, depth, [3, 3], scope=\"conv_3x3_1\", rate=6, activation_fn=None)\n",
        "\n",
        "        at_pool3x3_2 = slim.conv2d(net, depth, [3, 3], scope=\"conv_3x3_2\", rate=12, activation_fn=None)\n",
        "\n",
        "        at_pool3x3_3 = slim.conv2d(net, depth, [3, 3], scope=\"conv_3x3_3\", rate=18, activation_fn=None)\n",
        "\n",
        "        net = tf.concat((image_level_features, at_pool1x1, at_pool3x3_1, at_pool3x3_2, at_pool3x3_3), axis=3, name=\"concat\")\n",
        "        \n",
        "        net = slim.conv2d(net, depth, [1, 1], scope=\"conv_1x1_output\", activation_fn=None)\n",
        "        \n",
        "        return net\n",
        "\n",
        "\n",
        "def deeplab_v3(inputs, l2_regularizer, batch_norm_decay, batch_norm_epsilon, resnet_model, number_of_classes, output_stride, is_training, reuse):\n",
        "\n",
        "    # mean subtraction normalization\n",
        "    inputs = inputs - [_R_MEAN, _G_MEAN, _B_MEAN]\n",
        "\n",
        "    # inputs has shape - Original: [batch_size, 513, 513, 3]\n",
        "    with slim.arg_scope(resnet_utils.resnet_arg_scope(l2_regularizer, is_training, batch_norm_decay, batch_norm_epsilon)):\n",
        "        \n",
        "        resnet = getattr(resnet_v2, resnet_model)\n",
        "        \n",
        "        _, end_points = resnet(inputs, \n",
        "                               number_of_classes,\n",
        "                               is_training=is_training,\n",
        "                               global_pool=False,\n",
        "                               spatial_squeeze=False,\n",
        "                               output_stride=output_stride,\n",
        "                               reuse=reuse)\n",
        "\n",
        "        with tf.variable_scope(\"DeepLab_v3\", reuse = reuse):\n",
        "\n",
        "            # get block 4 feature outputs\n",
        "            net = end_points[resnet_model + '/block4']\n",
        "\n",
        "            net = atrous_spatial_pyramid_pooling(net, scope = \"ASPP_layer\", depth=256, reuse=reuse)\n",
        "\n",
        "            net = slim.conv2d(net, number_of_classes, [1, 1], activation_fn=None, normalizer_fn=None, scope='logits')\n",
        "\n",
        "            size = tf.shape(inputs)[1:3]\n",
        "            # resize the output logits to match the labels dimensions\n",
        "            net = tf.image.resize_bilinear(net, size)\n",
        "            \n",
        "            return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyYa05f8jXXz",
        "colab_type": "text"
      },
      "source": [
        "# Download the checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq2Cwej5jZkc",
        "colab_type": "code",
        "outputId": "9cb5e6f3-975d-451d-e18c-f5af4f0877c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "resnet_checkpoints_path = \"./resnet/checkpoints/\"\n",
        "download_resnet_checkpoint_if_necessary(resnet_checkpoints_path, resnet_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resnet: resnet_v2_50 successfully downloaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHy7wPHynLsD",
        "colab_type": "text"
      },
      "source": [
        "# Define the loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWdrRUcenKmW",
        "colab_type": "code",
        "outputId": "0e0a523b-8d14-493b-ba7c-1a5c79076320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# define the class labels\n",
        "class_labels = [v for v in range((number_of_classes+1))]\n",
        "class_labels[-1] = 255\n",
        "\n",
        "is_training_tf = tf.placeholder(tf.bool, shape=[])\n",
        "\n",
        "logits_tf = tf.cond(is_training_tf, true_fn = lambda: deeplab_v3(batch_images_tf, l2_regularizer, batch_norm_decay, batch_norm_epsilon, resnet_model, number_of_classes, output_stride, is_training=True, reuse=False),\n",
        "                                   false_fn = lambda: deeplab_v3(batch_images_tf, l2_regularizer, batch_norm_decay, batch_norm_epsilon, resnet_model, number_of_classes, output_stride, is_training=False, reuse=True))\n",
        "\n",
        "# get valid logits and labels (factor the 255 padded mask out for cross entropy)\n",
        "valid_labels_batch_tf, valid_logits_batch_tf = training.get_valid_logits_and_labels(annotation_batch_tensor=batch_labels_tf, \n",
        "                                                                                    logits_batch_tensor=logits_tf, \n",
        "                                                                                    class_labels=class_labels)\n",
        "\n",
        "cross_entropies = tf.nn.softmax_cross_entropy_with_logits_v2(logits=valid_logits_batch_tf,\n",
        "                                                             labels=valid_labels_batch_tf)\n",
        "\n",
        "loss = tf.reduce_mean(cross_entropies)\n",
        "\n",
        "# prediction_tensor is the argmax of logits\n",
        "predictions_tf = tf.argmax(logits_tf, axis=3)\n",
        "\n",
        "# Define the function for Mean IOU\n",
        "mean_iou, update_op = tf.contrib.metrics.streaming_mean_iou(tf.argmax(valid_logits_batch_tf, axis=1),\n",
        "                                                        tf.argmax(valid_labels_batch_tf, axis=1),\n",
        "                                                        num_classes=number_of_classes) \n",
        "\n",
        "\n",
        "with tf.variable_scope(\"optimizer_vars\"):\n",
        "    global_step = tf.Variable(0, trainable = False)\n",
        "    optimizer_1 = tf.train.AdamOptimizer(learning_rate = 0.00001).minimize(loss)\n",
        "    optimizer_2 = tf.train.AdamOptimizer(learning_rate = 0.000001).minimize(loss)\n",
        "    optimizer_3 = tf.train.AdamOptimizer(learning_rate = 0.0000001).minimize(loss)\n",
        "    \n",
        "optimizers = [optimizer_1, optimizer_2, optimizer_3]\n",
        "epochs = [7,10,10]    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0619 04:50:48.236351 139633178437504 deprecation_wrapper.py:119] From /content/deeplab_v3/resnet/resnet_v2.py:184: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0619 04:50:54.097642 139633178437504 deprecation.py:323] From /content/deeplab_v3/preprocessing/training.py:123: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0619 04:50:54.234465 139633178437504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:1179: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8XMHA-I9aKI",
        "colab_type": "text"
      },
      "source": [
        "## Function to overwrite the console output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umlAb4z99ZTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_overwrite(step, total_step, loss, mean_iou, operation):\n",
        "    sys.stdout.write('\\r')\n",
        "    \n",
        "    if operation == 'train':\n",
        "        sys.stdout.write(\"Train Steps: %d/%d  Loss: %.4f  Mean IOU: %.4f\" % (step, total_step, loss, mean_iou))\n",
        "        \n",
        "    else:\n",
        "        sys.stdout.write(\"Valid Steps: %d/%d  Loss: %.4f  Mean IOU: %.4f\" % (step, total_step, loss, mean_iou))\n",
        "        \n",
        "    sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhGZwrbqIRPX",
        "colab_type": "text"
      },
      "source": [
        "## Function to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBH94d3AIVGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    \n",
        "    train_steps = int(np.ceil(num_train_examples / float(batch_size)))\n",
        "    valid_steps = int(np.ceil(num_valid_examples / float(batch_size)))\n",
        "\n",
        "\n",
        "    for i, optimizer in enumerate(optimizers):\n",
        "\n",
        "            print('##################### Optimization: {} #####################'.format(i+1))\n",
        "\n",
        "            for epoch in range(epochs[i]):\n",
        "\n",
        "                loss_train = 0\n",
        "                loss_valid = 0\n",
        "\n",
        "                mean_iou_train = 0\n",
        "                mean_iou_valid = 0\n",
        "\n",
        "                running_loss = 0\n",
        "                running_mean_iou = 0\n",
        "\n",
        "                for step in range(1,train_steps):\n",
        "\n",
        "                    # Train our model on the batch of data\n",
        "                    loss_train_step, mean_iou_train_step, _, _ = sess.run([loss,mean_iou, update_op, optimizer], feed_dict = {handle: train_handle, is_training_tf: True})\n",
        "\n",
        "                    loss_train += loss_train_step\n",
        "                    mean_iou_train += mean_iou_train_step\n",
        "\n",
        "                    running_loss = loss_train/step\n",
        "                    running_mean_iou = mean_iou_train/step\n",
        "\n",
        "                    print_overwrite(step, train_steps, running_loss, running_mean_iou, 'train')\n",
        "\n",
        "                for step in range(1,valid_steps):\n",
        "\n",
        "                    loss_valid_step, mean_iou_valid_step, _ = sess.run([loss,mean_iou, update_op], feed_dict = {handle: valid_handle, is_training_tf: True})\n",
        "\n",
        "                    loss_valid += loss_valid_step\n",
        "                    mean_iou_valid += mean_iou_valid_step\n",
        "\n",
        "                    running_loss = loss_valid/step\n",
        "                    running_mean_iou = mean_iou_valid/step\n",
        "\n",
        "                    print_overwrite(step, valid_steps, running_loss, running_mean_iou, 'valid')\n",
        "\n",
        "                loss_train /= train_steps    \n",
        "                loss_valid /= valid_steps\n",
        "                mean_iou_train /= train_steps\n",
        "                mean_iou_valid /= valid_steps\n",
        "\n",
        "                print('\\n-----------------------------------------------------------------')\n",
        "                print (\"Epoch: \" + str(epoch+1) + \", Train Loss: \" + \"{:.4f}\".format(loss_train) + \", Train IOU: \" + \"{:.4f}\".format(mean_iou_train))\n",
        "                print (\"          Valid Loss: \" + \"{:.4f}\".format(loss_valid) + \", Valid IOU: \" + \"{:.4f}\".format(mean_iou_valid))\n",
        "                print('-----------------------------------------------------------------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C58Wt9uOAjnU",
        "colab_type": "text"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c06n2AUr_-rX",
        "colab_type": "code",
        "outputId": "5a2b61d2-aeb8-446e-9267-01526443a814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Declare the variable to restore\n",
        "variables_to_restore = slim.get_variables_to_restore(exclude=[resnet_model + \"/logits\", \"optimizer_vars\",\"DeepLab_v3/ASPP_layer\", \"DeepLab_v3/logits\"])\n",
        "\n",
        "# Add an operation to restore all the variables.\n",
        "restorer = tf.train.Saver(variables_to_restore)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # Create a saver.\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # load resnet checkpoints\n",
        "    restorer.restore(sess, \"./resnet/checkpoints/\" + resnet_model + \".ckpt\")\n",
        "    print(\"Model checkpoints for \" + resnet_model + \" restored!\")\n",
        "\n",
        "    train_handle = sess.run(train_iterator.string_handle())\n",
        "    valid_handle = sess.run(valid_iterator.string_handle())\n",
        "\n",
        "    sess.run(train_iterator.initializer)\n",
        "    sess.run(valid_iterator.initializer)\n",
        "\n",
        "    train()\n",
        "\n",
        "    # Save the variables \n",
        "    save_path = saver.save(sess, LOG_FOLDER + \"/train\" + \"/model.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0619 04:51:24.455890 139633178437504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model checkpoints for resnet_v2_50 restored!\n",
            "##################### Optimization: 1 #####################\n",
            "Valid Steps: 357/358  Loss: 0.4936  Mean IOU: 0.3693\n",
            "-----------------------------------------------------------------\n",
            "Epoch: 1, Train Loss: 0.8976, Train IOU: 0.2485\n",
            "          Valid Loss: 0.4922, Valid IOU: 0.3683\n",
            "-----------------------------------------------------------------\n",
            "Train Steps: 2/1063  Loss: 0.6077  Mean IOU: 0.3811"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}