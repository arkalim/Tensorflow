{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkalim/Tensorflow/blob/master/Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19HvFXDmErF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFcWXGu5FBWf",
        "colab_type": "text"
      },
      "source": [
        "### # Define a tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldT55kXQEVON",
        "colab_type": "code",
        "outputId": "7864b07b-cdcb-4df4-cef6-c72cb2b11f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "t = torch.Tensor()\n",
        "\n",
        "print(t)\n",
        "print(type(t))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([])\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC73rMWGE-mR",
        "colab_type": "text"
      },
      "source": [
        "This creates an empty tensor (tensor with no data), but we'll get to adding data in just a moment.\n",
        "\n",
        "### Tensor attributes\n",
        "First, letâ€™s look at a few tensor attributes. Every torch.Tensor has these attributes:\n",
        "\n",
        "* torch.dtype\n",
        "* torch.device\n",
        "* torch.layout (specifies how tensors are stored in the memory)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nkGeh6mEnEk",
        "colab_type": "code",
        "outputId": "eda9bf26-d21e-46ec-860a-3130c7e8db41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(t.dtype)\n",
        "print(t.device)\n",
        "print(t.layout)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float32\n",
            "cpu\n",
            "torch.strided\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBmeBl_dFtCi",
        "colab_type": "text"
      },
      "source": [
        "One thing to keep in mind about tensor data types is that tensor operations between tensors must happen between tensors with the same type of data.\n",
        "\n",
        "### Tensors have a torch.device\n",
        "The device, cpu in our case, specifies the device (CPU or GPU) where the tensor's data is allocated. This determines where tensor computations for the given tensor will be performed.\n",
        "\n",
        "**Note:** One thing to keep in mind about using multiple devices is that tensor operations between tensors must happen between tensors that exists on the same device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BALnBpItF6za",
        "colab_type": "code",
        "outputId": "c5a1ce62-79df-43b4-8400-0a0ee5d21990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device('cuda:0')\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaolUDBoI1vN",
        "colab_type": "text"
      },
      "source": [
        "## Creating tensors using data\n",
        "These are the primary ways of creating tensor objects (instances of the torch.Tensor class), with data (array-like) in PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0O1KCwAI3dD",
        "colab_type": "code",
        "outputId": "17dc7733-df1a-4968-f79b-e790311d17df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data = np.array([1,2,3])\n",
        "type(data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4NdtJiDJJHh",
        "colab_type": "code",
        "outputId": "ab0bf4b1-dcb6-4096-f4f1-cc1d3a05cee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# creating tensors using constructors\n",
        "torch.Tensor(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-8OsKYVLHYo",
        "colab_type": "text"
      },
      "source": [
        "### # creating tensors using factory function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM_vs_5dJRnf",
        "colab_type": "code",
        "outputId": "25b1d65f-b7bb-46f8-d05c-6e879173cf89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.tensor(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eemaLWNRJUQL",
        "colab_type": "code",
        "outputId": "deca14f3-b9d8-4b4e-df69-ddbcc5748c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.as_tensor(data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LE-O9zfJWdR",
        "colab_type": "code",
        "outputId": "6d2b4f8d-69fd-4f05-f3eb-9d03250a1d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.from_numpy(data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnFzpgJ9JzYP",
        "colab_type": "text"
      },
      "source": [
        "### Identity tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nXcC-6LJy19",
        "colab_type": "code",
        "outputId": "5959f026-dbb5-416b-a95d-2e27f89c339f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "torch.eye(3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCuJwTbNJ-b_",
        "colab_type": "text"
      },
      "source": [
        "### Other tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BX57J2bKA1h",
        "colab_type": "code",
        "outputId": "965af2ea-49c7-47da-853f-229efbd20548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "torch.zeros(3,4)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPWfiEZbKOOd",
        "colab_type": "code",
        "outputId": "12d554a7-e4f8-4782-868a-429b030ebbae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "torch.ones(4,3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLAHGlndKRbW",
        "colab_type": "code",
        "outputId": "fc20ee9a-e325-4ed7-ce6a-287320dab026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.rand(3)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0265, 0.8900, 0.0895])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZa_9FDrLehF",
        "colab_type": "text"
      },
      "source": [
        "# Creating tensors from data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QXkM2ROLkzw",
        "colab_type": "code",
        "outputId": "54a301e0-8b4b-48ef-b8f1-376419865a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.tensor(np.array([1,2,3]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJkePKaRLryC",
        "colab_type": "code",
        "outputId": "d5bc10cc-4bc9-4955-87b3-0fe6f96dc9ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.tensor(np.array([1.,2.,3.]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgyE9nh-LxTL",
        "colab_type": "code",
        "outputId": "99a858b3-146d-45d4-93ea-4b6132781f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.tensor(np.array([1,2,3]), dtype = torch.float32)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jdLDUZhM48F",
        "colab_type": "text"
      },
      "source": [
        "## Memory Sharing and Copying between the data and the tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHj2IIH5M4mT",
        "colab_type": "code",
        "outputId": "966b0952-943f-4abb-be15-f5975ff80dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data = np.array([1,2,3])\n",
        "data"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHEXKyeUNHXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = torch.Tensor(data)\n",
        "t2 = torch.tensor(data)\n",
        "t3 = torch.as_tensor(data)\n",
        "t4 = torch.from_numpy(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTa_hm4JOZvl",
        "colab_type": "text"
      },
      "source": [
        "Modifying the  data but not the tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_1KseCMNxjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[0] = 0\n",
        "data[1] = 0\n",
        "data[2] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c9z294yN01K",
        "colab_type": "code",
        "outputId": "f9ddbc74-d30c-4e8a-c85b-d9f59e35ea0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(t1)\n",
        "print(t2)\n",
        "print(t3)\n",
        "print(t4)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([1, 2, 3])\n",
            "tensor([0, 0, 0])\n",
            "tensor([0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb2A9sPYOnss",
        "colab_type": "text"
      },
      "source": [
        "This concludes that 1st two methods create a copy of the data, whereas the last two methods share the same memory for both data and tensor which means the code will run faster since no copying is needed.\n",
        "\n",
        "## Flatten, Reshape and Squeeze Explained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7hAk__aPyYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = torch.tensor([\n",
        "    [1,1,1,1],\n",
        "    [2,2,2,2],\n",
        "    [3,3,3,3]\n",
        "], dtype=torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-SQ2b_WRAYK",
        "colab_type": "code",
        "outputId": "95e661dc-a44b-4b91-9857-7ab055f11ec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6MH0dc_RDcc",
        "colab_type": "code",
        "outputId": "98e8f9cd-3737-4247-aae8-1d1e40fb5b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t.size()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huCGcIqPRNER",
        "colab_type": "code",
        "outputId": "8bc078df-7771-4c5e-8060-e13fc9686001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# find number of elements in the tensor\n",
        "t.numel()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUxy7mtkRVUd",
        "colab_type": "code",
        "outputId": "4fbe6f4c-cc1f-41cd-c43f-839d94c8c3f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# find no. of axes\n",
        "len(t.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeQalBvzRn5d",
        "colab_type": "code",
        "outputId": "d9c8056e-8003-46f4-d311-843d8f4e0163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t.reshape(-1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ3LVRQsRsro",
        "colab_type": "code",
        "outputId": "45cf4122-95c1-4551-95d6-37bca4e0a037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "t.reshape(-1,2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.],\n",
              "        [2., 2.],\n",
              "        [2., 2.],\n",
              "        [3., 3.],\n",
              "        [3., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czsw9A4uR6Y0",
        "colab_type": "code",
        "outputId": "5bcc27aa-18d0-4cfb-f006-33432e580d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "t.reshape(2,2,3)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1.],\n",
              "         [1., 2., 2.]],\n",
              "\n",
              "        [[2., 2., 3.],\n",
              "         [3., 3., 3.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsgFdW3bSAFh",
        "colab_type": "code",
        "outputId": "e427795e-d46c-40fe-acd7-e26f63c5e208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# squeeze removes the axis with length of 1\n",
        "t.reshape(1,12).squeeze()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRAJkEClSR-w",
        "colab_type": "code",
        "outputId": "f5b2d272-5461-449c-a09d-14f29fa58293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# squeeze adds an axis with length of 1 along the specified dimension\n",
        "t.reshape(12).unsqueeze(dim = 0)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDYWbFpsSZv5",
        "colab_type": "code",
        "outputId": "d1c86d9d-7a40-4fd1-9e07-17bbda83d56e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# squeeze adds an axis with length of 1 along the specified dimension\n",
        "t.reshape(12).unsqueeze(dim = 1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [3.],\n",
              "        [3.],\n",
              "        [3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvPxX_-sVbtf",
        "colab_type": "code",
        "outputId": "59c1122d-6d95-4d40-bbaf-f3390ffa1136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t.flatten()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3evupJjV2nt",
        "colab_type": "code",
        "outputId": "3e63b724-acc7-4198-ba6f-a5f332eccc91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# concatenating\n",
        "\n",
        "a = torch.tensor([\n",
        "    [1,2,3],\n",
        "    [1,2,3]\n",
        "])\n",
        "\n",
        "b = torch.tensor([\n",
        "    [4,5,6],\n",
        "    [4,5,6]\n",
        "])\n",
        "\n",
        "torch.cat((a,b), dim = 0)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnwmpPk8Wam5",
        "colab_type": "code",
        "outputId": "ace3c43c-d054-49e7-8bf6-2caa33ac72f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "torch.cat((a,b), dim = 1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 4, 5, 6],\n",
              "        [1, 2, 3, 4, 5, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDGRw8P5WwxL",
        "colab_type": "text"
      },
      "source": [
        "# CNN Flatten Operation Visualized - Tensor Batch Processing for Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJOPowtSWyRN",
        "colab_type": "code",
        "outputId": "1afc1532-20d6-4f5b-c95d-ed2b82bc39e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "a = torch.ones(3,4)\n",
        "b = a + 1\n",
        "c = b + 1\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2.],\n",
            "        [2., 2., 2., 2.]])\n",
            "tensor([[3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp_tlu18YIyV",
        "colab_type": "code",
        "outputId": "559447b3-3171-4fec-8fa6-41a7bb680d22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# stack the tensors on top of each other\n",
        "torch.stack([a,b,c])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]],\n",
              "\n",
              "        [[2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2.]],\n",
              "\n",
              "        [[3., 3., 3., 3.],\n",
              "         [3., 3., 3., 3.],\n",
              "         [3., 3., 3., 3.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgyUYRkMYYVQ",
        "colab_type": "code",
        "outputId": "aaf43dc1-0590-438d-d5cf-67ded7dce85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "# often we need to unsqueeze grayscale images before feeding them to a neural net\n",
        "\n",
        "torch.unsqueeze(torch.stack([a,b,c]), dim = 1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.],\n",
              "          [1., 1., 1., 1.]]],\n",
              "\n",
              "\n",
              "        [[[2., 2., 2., 2.],\n",
              "          [2., 2., 2., 2.],\n",
              "          [2., 2., 2., 2.]]],\n",
              "\n",
              "\n",
              "        [[[3., 3., 3., 3.],\n",
              "          [3., 3., 3., 3.],\n",
              "          [3., 3., 3., 3.]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zca8LdF6Y0Gp",
        "colab_type": "text"
      },
      "source": [
        "Brackets are arranged in the order [batch, channel, height, width]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX6xtPtRZAgI",
        "colab_type": "code",
        "outputId": "3443d62e-7333-4708-dc70-4cdd375c7cdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t = torch.unsqueeze(torch.stack([a,b,c]), dim = 1)\n",
        "print(t.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 3, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WdMt5FjZ8st",
        "colab_type": "code",
        "outputId": "9ac5f40c-f753-498f-fc07-6ba060423162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# first image in the batch\n",
        "t[0]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7R9-XRJaBFF",
        "colab_type": "code",
        "outputId": "224b3250-e5db-4ab6-aadb-99226d58fd3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# first color channel of the first image\n",
        "t[0][0]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi-gKHCuaJZH",
        "colab_type": "code",
        "outputId": "9e5b85ce-98bd-40c0-ac73-c40c499668f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# first row of first color channel of the first image\n",
        "t[0][0][0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_59sFQdaqeR",
        "colab_type": "code",
        "outputId": "141b7a23-f376-4f8a-cf55-f34f4f4c0504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# when flattening images to feed to our CNN we don't want to flatten in batch axis\n",
        "# this is specified using start_dim which tells the function which axis to start flattening \n",
        "t.flatten(start_dim = 1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM5iZSChYEoI",
        "colab_type": "text"
      },
      "source": [
        "# Tensor Reduction Operations\n",
        "A reduction operation on a tensor is an operation that reduces the number of elements contained within the tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQY-6bAdS-4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = torch.tensor([\n",
        "    [1,2,3],\n",
        "    [4,5,6],\n",
        "    [7,8,9]\n",
        "], dtype = torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Be6QV5WY4Mc",
        "colab_type": "code",
        "outputId": "1620b434-12f0-4266-944b-19f537b994b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# sum of all the elements in the tensor\n",
        "t.sum()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(45.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FiwgZ5lZByI",
        "colab_type": "code",
        "outputId": "e1eb1f74-34dc-4b1b-9857-b777524ccff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# product of all the elements in the tensor\n",
        "t.prod()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(362880.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DvjhWtbZGN9",
        "colab_type": "code",
        "outputId": "2e88061d-5042-4849-bd73-a94f32b7772f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# mean of all the elements in the tensor\n",
        "t.mean()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSp0TJuAZRs6",
        "colab_type": "code",
        "outputId": "af238864-15f0-40a4-ce4a-8d9a74b88161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# standard deviation of all the elements in the tensor\n",
        "t.std()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.7386)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_LDWddOZb9G",
        "colab_type": "code",
        "outputId": "ebe9c655-59b2-44ec-fd56-b1e95ef80d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# number of elements in the tensor\n",
        "t.numel()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsCQP9IDaGwq",
        "colab_type": "text"
      },
      "source": [
        "All of these tensor methods reduce the tensor to a single element scalar valued tensor by operating on all the tensor's elements.\n",
        "\n",
        "### We can select axes for reduction operation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L85yCIhOaVx5",
        "colab_type": "code",
        "outputId": "6065bd92-4960-40c9-97bc-9fb1ac389bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(t.mean(dim = 0))\n",
        "print(t.mean(dim = 1))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4., 5., 6.])\n",
            "tensor([2., 5., 8.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm3ncJjEajaS",
        "colab_type": "code",
        "outputId": "7fde9024-3eef-4cf0-d2bd-1e43fb9acb92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(t.sum(dim = 0))\n",
        "print(t.sum(dim = 1))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([12., 15., 18.])\n",
            "tensor([ 6., 15., 24.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGhnQx7gbwUd",
        "colab_type": "code",
        "outputId": "d375554f-0489-4508-87b8-3684a27fac9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# finding maximum value\n",
        "t.max()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1ck46jNb0lw",
        "colab_type": "code",
        "outputId": "9559ae6e-8bf2-4829-e868-58091ea221b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# finding argmax\n",
        "t.argmax()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er_wXPm8qAIa",
        "colab_type": "text"
      },
      "source": [
        "## Preparing dataset(Fashion MNIST) \n",
        "\n",
        "Here, we will learn ETL pipeline (extract, transform, load)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdHMMN1IqD_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VdQXZAxsW9v",
        "colab_type": "text"
      },
      "source": [
        "torch: The top-level PyTorch package and tensor library.\n",
        "\n",
        "torch.nn:\tA subpackage that contains modules and extensible classes for building neural networks.\n",
        "\n",
        "torch.optim:\tA subpackage that contains standard optimization operations like SGD and Adam.\n",
        "\n",
        "torch.nn.functional: A functional interface that contains typical operations used for building neural networks like loss functions and convolutions.\n",
        "\n",
        "torchvision:\tA package that provides access to popular datasets, model architectures, and image transformations for computer vision.\n",
        "\n",
        "torchvision.transforms:\tAn interface that contains common transforms for image processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aChwQNwssTqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from plotcm import plot_confusion_matrix\n",
        "\n",
        "import pdb\n",
        "\n",
        "torch.set_printoptions(linewidth=120)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5lCZZhLt09m",
        "colab_type": "text"
      },
      "source": [
        "torch.utils.data.Dataset:\tAn abstract class for representing a dataset.\n",
        "torch.utils.data.DataLoader:\tWraps a dataset and provides access to the underlying data.\n",
        "\n",
        "An abstract class is a Python class that has methods we must implement, so we can create a custom dataset by creating a subclass that extends the functionality of the Dataset class.\n",
        "\n",
        "To create a custom dataset using PyTorch, we extend the Dataset class by creating a subclass that implements these required methods. Upon doing this, our new subclass can then be passed to the a PyTorch DataLoader object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlfhCJISu3YV",
        "colab_type": "code",
        "outputId": "8163e49a-ca67-4af3-d22a-a8d496dbbf67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "# Since we want our images to be transformed into tensors,\n",
        "# we use the built-in transforms.ToTensor() transformation, \n",
        "# and since this dataset is going to be used for training,\n",
        "# weâ€™ll name the instance train_set.\n",
        "\n",
        "# download the dataset if it doesn't exist on the disk\n",
        "\n",
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root='./data/FashionMNIST'\n",
        "    ,train=True\n",
        "    ,download=True\n",
        "    ,transform=transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:01, 13935598.38it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 79764.46it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:01, 4033094.37it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 33633.03it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p018e-E8wSTK",
        "colab_type": "text"
      },
      "source": [
        "All subclasses of the Dataset class must override __len__, that provides the size of the dataset, and __getitem__, supporting integer indexing in range from 0 to len(self) exclusive.\n",
        "\n",
        "Specifically, there are two methods that are required to be implemented. The __len__ method which returns the length of the dataset, and the __getitem__ method that gets an element from the dataset at a specific index location within the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TKb3vObw9Yj",
        "colab_type": "text"
      },
      "source": [
        "## Exploring the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtZr7seZw8qm",
        "colab_type": "code",
        "outputId": "22eab4cc-6071-4a5a-f1fe-cc6a57d23966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_set)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW_vJC9SxJqV",
        "colab_type": "code",
        "outputId": "e980029f-dc3f-4566-e46d-c02b944eec00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# print the target labels for all the 60000 images\n",
        "train_set.targets"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 0, 0,  ..., 3, 0, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq2BZYhRxjpV",
        "colab_type": "code",
        "outputId": "83b6d7c5-534a-4163-9aff-81b475b0a37a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# finding unique labels \n",
        "torch.unique(train_set.targets)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGtrTHLZx6X6",
        "colab_type": "code",
        "outputId": "de689ffc-7f00-4cdf-f0ff-919026d9966f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# find how many of each labels exist in the dataset\n",
        "train_set.targets.bincount()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXDhxiUeyGP4",
        "colab_type": "text"
      },
      "source": [
        "This shows us that the Fashion-MNIST dataset is uniform with respect to the number of samples from each class. This means we have 6000 samples for each class. As a result, this dataset is said to be balanced. If the classes had a varying number of samples, we would call the set an unbalanced dataset.\n",
        "\n",
        "## Accessing data in the training set\n",
        "To access an individual element from the training set, we first pass the train_set object to Pythonâ€™s iter() built-in function, which returns an object representing a stream of data.\n",
        "\n",
        "With the stream of data, we can use Python built-in next() function to get the next data element in the stream of data. From this we are expecting to get a single sample, so weâ€™ll name the result accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEuF6jUgyHFu",
        "colab_type": "code",
        "outputId": "e0389acd-4328-4718-941a-4d596c17343b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "# get the next element (not batch)\n",
        "image, label = next(iter(train_set))\n",
        "\n",
        "print(type(image))\n",
        "print(type(label))\n",
        "\n",
        "print(image.shape)\n",
        "print(label)\n",
        "\n",
        "img = image.squeeze()\n",
        "\n",
        "plt.imshow(img, cmap = 'gray')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'int'>\n",
            "torch.Size([1, 28, 28])\n",
            "9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa2ae0eba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCD9QqP8HS8xVdqsDFvAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW-t6rn71c0x",
        "colab_type": "text"
      },
      "source": [
        "## PyTorch DataLoader: Working with batches of data\n",
        "We get a batch from the loader in the same way that we saw with the training set. We use the iter() and next() functions.\n",
        "\n",
        "There is one thing to notice when working with the data loader. If shuffle=True, then the batch will be different each time a call to next occurs. With shuffle=True, the first samples in the training set will be returned on the first call to next. The shuffle functionality is turned off by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daC-FLKYvzVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To create a DataLoader wrapper for our training set, we do it like this:\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=10, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUR0oIci1-_2",
        "colab_type": "code",
        "outputId": "2e45ebc9-95fd-4d7f-9837-1f018a34d06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 1, 28, 28])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1excRu_K4O7y",
        "colab_type": "text"
      },
      "source": [
        "(batch size, number of color channels, image height, image width)\n",
        "\n",
        "To plot a batch of images, we can use the torchvision.utils.make_grid() function to create a grid that can be plotted like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2NSM9wM4QL9",
        "colab_type": "code",
        "outputId": "7672af88-7775-4b8f-b9c5-cc7153ee4f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "# make a grid with the images \n",
        "grid = torchvision.utils.make_grid(images, nrow=10)\n",
        "\n",
        "plt.figure(figsize = (15,4))\n",
        "plt.imshow(np.transpose(grid,(1,2,0)))\n",
        "#we can also use: grid.permute(1,2,0)\n",
        "\n",
        "print('Labels: ',labels)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels:  tensor([3, 2, 2, 2, 2, 2, 5, 5, 3, 0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2wAAAB7CAYAAAAIVwPvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGOMMX3K/weN+4A0Y1HJQAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjjVppQB6N2j",
        "colab_type": "text"
      },
      "source": [
        "# Build PyTorch CNN - Object Oriented Neural Networks\n",
        "To build neural networks in PyTorch, we extend the torch.nn.Module PyTorch class. This means we need to utilize a little bit of object oriented programming (OOP) in Python.\n",
        "\n",
        "Weâ€™ll do a quick OOP review in this post to cover the details needed for working with PyTorch neural networks, but if you find that you need more, the Python docs have an overview tutorial [here.](https://https://docs.python.org/3/tutorial/classes.html)\n",
        "\n",
        "## PyTorchâ€™s torch.nn package\n",
        "To build neural networks in PyTorch, we use the torch.nn package, which is PyTorchâ€™s neural network (nn) library. We typically import the package like so:\n",
        "\n",
        "\n",
        "```\n",
        "import torch.nn as nn\n",
        "```\n",
        "\n",
        "## PyTorch's nn.Module class\n",
        "As we know, deep neural networks are built using multiple layers. This is what makes the network deep. Each layer in a neural network has two primary components:\n",
        "\n",
        "A transformation (code)\n",
        "A collection of weights (data)\n",
        "Like many things in life, this fact makes layers great candidates to be represented as objects using OOP. OOP is short for object oriented programming.\n",
        "\n",
        "In fact, this is the case with PyTorch. Within the nn package, there is a class called Module, and it is the base class for all of neural network modules which includes layers.\n",
        "\n",
        "This means that all of the layers in PyTorch extend the nn.Module class and inherit all of PyTorchâ€™s built-in functionality within the nn.Module class. In OOP this concept is known as inheritance.\n",
        "\n",
        "Even neural networks extend the nn.Module class. This makes sense because neural networks themselves can be thought of as one big layer \n",
        "\n",
        "### PyTorch nn.Modules have a forward() method\n",
        "Forward pass is defined in this method. When we are building layers and networks, we must provide an implementation of the forward() method. The forward method is the actual transformation.\n",
        "\n",
        "### PyTorchâ€™s nn.functional package\n",
        "When we implement the forward() method of our nn.Module subclass, we will typically use functions from the nn.functional package. This package provides us with many neural network operations that we can use for building layers. In fact, many of the nn.Module layer classes use nn.functional functions to perform their operations.\n",
        "\n",
        "## Steps to create a model in PyTorch\n",
        "* Create a neural network class that extends the nn.Module base class.\n",
        "* In the class constructor, define the networkâ€™s layers as class attributes using pre-built layers from torch.nn.\n",
        "* Use the networkâ€™s layer attributes as well as operations from the nn.functional API to define the networkâ€™s forward pass.\n",
        "\n",
        "## Step 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRkD8Psk6NS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a simple class\n",
        "class Network:\n",
        "    def __init__(self):\n",
        "        self.layer = None\n",
        "\n",
        "    def forward(self, t):\n",
        "        t = self.layer(t)\n",
        "        return t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVWZDnniVWW0",
        "colab_type": "text"
      },
      "source": [
        "This gives us a simple network class that has a single dummy layer inside the constructor and a dummy implementation for the forward function.\n",
        "\n",
        "The implementation for the forward() function takes in a tensor t and transforms it using the dummy layer. After the tensor is transformed, the new tensor is returned.\n",
        "\n",
        "This is a good start, but the class hasnâ€™t yet extended the nn.Module class. To make our Network class extend nn.Module, we must do two additional things:\n",
        "\n",
        "* Specify the nn.Module class in parentheses on line 1.\n",
        "* Insert a call to the super class constructor on line 3 inside the constructor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVkY_BEGVXOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network,self).__init__()\n",
        "        self.layer = None\n",
        "        \n",
        "    def forward(self,t):\n",
        "        t = self.Layer(t)\n",
        "        return t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9WGnDQlWWAd",
        "colab_type": "text"
      },
      "source": [
        "These changes transform our simple neural network into a PyTorch neural network because we are now extending PyTorch's nn.Module base class.\n",
        "\n",
        "With this, we are done! Now we have a Network class that has all of the functionality of the PyTorch nn.Module class.\n",
        "\n",
        "## Step 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMRauA6GWsfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "        self.out = nn.Linear(in_features=60, out_features=10)\n",
        "        \n",
        "    def forward(self,t): \n",
        "        # implement the forward pass\n",
        "        return t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZXPdct5Y1-A",
        "colab_type": "text"
      },
      "source": [
        "Each of our layers extends PyTorch's neural network Module class. For each layer, there are two primary items encapsulated inside, a forward function definition and a weight tensor.\n",
        "\n",
        "The weight tensor inside each layer contains the weight values that are updated as the network learns during the training process, and this is the reason we are specifying our layers as attributes inside our Network class.\n",
        "\n",
        "PyTorch's neural network Module class keeps track of the weight tensors inside each layer. The code that does this tracking lives inside the nn.Module class, and since we are extending the neural network module class, we inherit this functionality automatically.\n",
        "\n",
        "Remember, inheritance is one of those object oriented concepts that we talked about last time. All we have to do to take advantage of this functionality is assign our layers as attributes inside our network module, and the Module base class will see this and register the weights as learnable parameters of our network.\n",
        "\n",
        "#### Parameter vs Argument\n",
        "While parameters are used in function definitions as place-holders while arguments are the actual values that are passed to the function. The parameters can be thought of as local variables that live inside a function.\n",
        "\n",
        "In our network's case, the names are the parameters and the values that we have specified are the arguments.\n",
        "\n",
        "### Getting an instance of the Network\n",
        "Remember, to get an object instance of our Network class, we type the class name followed by parentheses. When this code executes, the code inside the __init__ class constructor will run, assigning our layers as attributes before the object instance is returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwX5x-SbZSZJ",
        "colab_type": "code",
        "outputId": "bc7ebfe2-c9ba-4d97-be2e-49b82959f3e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "network = Network()\n",
        "print(network)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
            "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMp1vorhgG7c",
        "colab_type": "text"
      },
      "source": [
        "This nice string representation comes from nn.Module base class. We can override this functionality using __repr__() "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVfJNjI7gYIR",
        "colab_type": "code",
        "outputId": "8b5d52c7-118c-4f71-bd1f-29a9e2f476af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "class Network(nn.Module):\n",
        "    \n",
        "    # constructor function constructs objects\n",
        "    def __init__(self):\n",
        "        super(Network,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "        self.out = nn.Linear(in_features=60, out_features=10)\n",
        "        \n",
        "    def forward(self,t): \n",
        "        # implement the forward pass\n",
        "        return t\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return 'Simple Model'\n",
        "    \n",
        "network = Network()\n",
        "print(network)    "
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2zaccejhn-F",
        "colab_type": "text"
      },
      "source": [
        "### Accessing specific layers of the model\n",
        "we access attributes and methods of objects using dot notation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwPmaOYchnli",
        "colab_type": "code",
        "outputId": "b1876c7b-7525-4c3a-b8a6-6edf3f6b165d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "network.conv1"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0SuGT26iE0r",
        "colab_type": "text"
      },
      "source": [
        "### Accessing weights of a layer in the network\n",
        "This is a good example that showcases how objects are nested. We first access the conv layer object that lives inside the network object.\n",
        "\n",
        "Then, we access the weight tensor object that lives inside the conv layer object, so all of these objects are chained or linked together.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h823-pZeiJHf",
        "colab_type": "code",
        "outputId": "d43d23d4-a0cd-4409-9720-8d0ffed41948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "print(network.conv1.weight.shape)\n",
        "print(network.conv1.weight)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 1, 5, 5])\n",
            "Parameter containing:\n",
            "tensor([[[[-0.0919,  0.1548, -0.0552, -0.1840,  0.1948],\n",
            "          [-0.0446,  0.1990,  0.0299,  0.0940, -0.0937],\n",
            "          [-0.1648,  0.0240,  0.0933, -0.1895,  0.0139],\n",
            "          [ 0.0160,  0.0198,  0.1206, -0.0760, -0.0688],\n",
            "          [ 0.1692,  0.0137,  0.0375, -0.1956,  0.1356]]],\n",
            "\n",
            "\n",
            "        [[[-0.0597,  0.1695,  0.0258, -0.1834,  0.1185],\n",
            "          [ 0.0633,  0.0134, -0.1708, -0.0287,  0.0189],\n",
            "          [-0.1834,  0.1581,  0.1628,  0.0663,  0.1070],\n",
            "          [-0.1178,  0.0575,  0.0450, -0.1073, -0.1695],\n",
            "          [ 0.0213,  0.0126,  0.0244, -0.0152,  0.1942]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0781,  0.1767, -0.0103, -0.0761, -0.0909],\n",
            "          [-0.1743,  0.0172, -0.0245, -0.1450,  0.1348],\n",
            "          [ 0.1413, -0.0834, -0.1222, -0.0198,  0.1272],\n",
            "          [ 0.1682, -0.0972, -0.0656,  0.1159, -0.1758],\n",
            "          [-0.0223, -0.1861, -0.1667, -0.0264, -0.1950]]],\n",
            "\n",
            "\n",
            "        [[[-0.0806,  0.1407, -0.1901, -0.1906, -0.0671],\n",
            "          [ 0.1875, -0.1765, -0.0707,  0.0718,  0.0693],\n",
            "          [ 0.0468,  0.0470,  0.0661,  0.0321, -0.0746],\n",
            "          [ 0.1036, -0.0855,  0.0654, -0.0670,  0.0945],\n",
            "          [-0.0007,  0.1927, -0.1569, -0.0152,  0.1977]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0393,  0.0904, -0.0170, -0.0855, -0.1370],\n",
            "          [-0.1996, -0.0622,  0.0527,  0.1276,  0.0534],\n",
            "          [ 0.1357, -0.0888, -0.1372,  0.0575, -0.1983],\n",
            "          [-0.1003,  0.0223,  0.0044,  0.1473, -0.0177],\n",
            "          [ 0.0719, -0.1420,  0.0953, -0.0310,  0.0173]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0971, -0.0715, -0.0473,  0.1090,  0.1435],\n",
            "          [-0.1226,  0.0517, -0.1956, -0.1075,  0.0617],\n",
            "          [ 0.1206, -0.1574, -0.0303,  0.1056, -0.0804],\n",
            "          [ 0.1279,  0.1569,  0.0276,  0.1564,  0.1329],\n",
            "          [-0.0831, -0.0200,  0.1505, -0.0577,  0.0791]]]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjgj7wIGioHJ",
        "colab_type": "text"
      },
      "source": [
        "**Note:** One thing to notice about the weight tensor output is that it says parameter containing at the top of the output. This is because this particular tensor is a special tensor because its values or scalar components are learnable parameters of our network.\n",
        "\n",
        "### PyTorch Parameter Class\n",
        "To keep track of all the weight tensors inside the network. PyTorch has a special class called Parameter. The Parameter class extends the tensor class, and so the weight tensor inside every layer is an instance of this Parameter class. This is why we see the Parameter containing text at the top of the string representation output.\n",
        "### Accessing the Networks Parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF65ahjuis9-",
        "colab_type": "code",
        "outputId": "2eecb978-ce1f-427e-a426-154bbf8765b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "for param in network.parameters():\n",
        "    print(param.shape)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 1, 5, 5])\n",
            "torch.Size([6])\n",
            "torch.Size([12, 6, 5, 5])\n",
            "torch.Size([12])\n",
            "torch.Size([120, 192])\n",
            "torch.Size([120])\n",
            "torch.Size([60, 120])\n",
            "torch.Size([60])\n",
            "torch.Size([10, 60])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw5TMuCRn8_2",
        "colab_type": "code",
        "outputId": "bafdb820-2612-4c1f-8a51-6d6b3e4a325b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "for name, param in network.named_parameters():\n",
        "    print('Name: {}      Shape: {}'.format(name, param.shape))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: conv1.weight      Shape: torch.Size([6, 1, 5, 5])\n",
            "Name: conv1.bias      Shape: torch.Size([6])\n",
            "Name: conv2.weight      Shape: torch.Size([12, 6, 5, 5])\n",
            "Name: conv2.bias      Shape: torch.Size([12])\n",
            "Name: fc1.weight      Shape: torch.Size([120, 192])\n",
            "Name: fc1.bias      Shape: torch.Size([120])\n",
            "Name: fc2.weight      Shape: torch.Size([60, 120])\n",
            "Name: fc2.bias      Shape: torch.Size([60])\n",
            "Name: out.weight      Shape: torch.Size([10, 60])\n",
            "Name: out.bias      Shape: torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR154PFSVdUr",
        "colab_type": "text"
      },
      "source": [
        "### Callable Layers and Neural Networks\n",
        "Instead of calling the forward() method directly, we call the object instance. After the object instance is called, the __call__() method is invoked under the hood, and the __call__() in turn invokes the forward() method. This applies to all PyTorch neural network modules, namely, networks and layers.\n",
        "\n",
        "## Step 3 Forward Pass\n",
        "\n",
        "Each of these layers is comprised of a collection of weights (data) and a collection operations (code). The weights are encapsulated inside the nn.Conv2d() class instance. The relu() and the max_pool2d() calls are just pure operations. Neither of these have weights, and this is why we call them directly from the nn.functional API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p09ONW5TWBJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "    \n",
        "    # constructor function constructs objects\n",
        "    def __init__(self):\n",
        "        super(Network,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "        self.out = nn.Linear(in_features=60, out_features=10)\n",
        "        \n",
        "    def forward(self,t): \n",
        "        \n",
        "        t = self.conv1(t)\n",
        "        t = F.relu(t)\n",
        "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
        "        \n",
        "        t = self.conv2(t)\n",
        "        t = F.relu(t)\n",
        "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
        "        \n",
        "        t = t.reshape(-1, 12 * 4 * 4)\n",
        "        t = self.fc1(t)\n",
        "        t = F.relu(t)\n",
        "        \n",
        "        t = self.fc2(t)\n",
        "        t = F.relu(t)\n",
        "        \n",
        "        t = self.out(t)\n",
        "        #t = F.softmax(t, dim = 1)\n",
        "       \n",
        "        return t\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5C5kI57aPlU",
        "colab_type": "text"
      },
      "source": [
        "The values inside each of the ten components will correspond to the prediction value for each of our prediction classes.\n",
        "\n",
        "Inside the network we usually use relu() as our non-linear activation function, but for the output layer, whenever we have a single category that we are trying to predict, we use softmax(). The softmax function returns a positive probability for each of the prediction classes, and the probabilities sum to 1.\n",
        "\n",
        "\n",
        " \n",
        "However, in our case, we won't use softmax() because the loss function that we'll use, F.cross_entropy(), implicitly performs the softmax() operation on its input, so we'll just return the result of the last linear transformation.\n",
        "\n",
        "The implication of this is that our network will be trained using the softmax operation but will not need to compute the additional operation when the network is used for inference after the training process is complete.\n",
        "\n",
        "### Predicting with the network: Forward pass\n",
        "Before we being, we are going to turn off PyTorchâ€™s gradient calculation feature. This will stop PyTorch from automatically building a computation graph as our tensor flows through the network.\n",
        "\n",
        "The computation graph keeps track of the network's mapping by tracking each computation that happens. The graph is used during the training process to calculate the derivative (gradient) of the loss function with respect to the networkâ€™s weights.\n",
        "\n",
        "Since we are not training the network yet, we arenâ€™t planning on updating the weights, and so we donâ€™t require gradient calculations. We will turn this back on when training begins.\n",
        "\n",
        "### Turning off the computation graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ6V8_XpaRhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a10aa84f-a625-4385-adca-bc79010605b2"
      },
      "source": [
        "# turning off dynamic computational graph\n",
        "torch.set_grad_enabled(False)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7fa2abfda828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "109b5AxhdL22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "1b2ecd24-bace-4461-8cc5-b0805a9ee640"
      },
      "source": [
        "# create an instance of the Network class\n",
        "network = Network()\n",
        "\n",
        "image, label = next(iter(train_set))\n",
        "print(image.shape)\n",
        "\n",
        "# unsqueeze to add a dimension for batch\n",
        "image = image.unsqueeze(0)\n",
        "print(image.shape)\n",
        "\n",
        "pred = network(image)\n",
        "print(pred)\n",
        "\n",
        "print('Prediction: {}'.format(pred.argmax(dim = 1)))\n",
        "print('Target Label: {}'.format(label))\n",
        "\n",
        "# If we want th epredictions as probability distribution\n",
        "print('Prediction: {}'.format(F.softmax(pred,dim = 1)))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([1, 1, 28, 28])\n",
            "tensor([[-0.0967, -0.0576,  0.0862, -0.0516, -0.1085, -0.0490,  0.0748,  0.0182,  0.1227, -0.0943]])\n",
            "Prediction: tensor([8])\n",
            "Target Label: 9\n",
            "Prediction: tensor([[0.0919, 0.0956, 0.1104, 0.0961, 0.0908, 0.0964, 0.1091, 0.1031, 0.1145, 0.0921]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmrY6uopm56R",
        "colab_type": "text"
      },
      "source": [
        "The prediction in this case is incorrect, which is what we expect because the weights in the network were generated randomly.\n",
        "\n",
        "### Predicting on a batch of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDSDSSNZm7Gy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c6626bc3-0814-4dfc-9c6a-b3852531483e"
      },
      "source": [
        "from torch.utils.data import DataLoader \n",
        "\n",
        "data_loader = DataLoader(train_set, batch_size = 10, shuffle = True)\n",
        "\n",
        "images, labels = next(iter(data_loader))\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "predictions = network(images)\n",
        "\n",
        "print(predictions.argmax(dim = 1))\n",
        "print(labels)\n",
        "\n",
        "# Element wise comparison between labels and predictions\n",
        "# This can be used to calculate accuracy\n",
        "print(predictions.argmax(dim = 1).eq(labels))\n",
        "\n",
        "# Find number of correct predictions\n",
        "# .item() returns the value of a 1x1 tensor (scalar)\n",
        "print(predictions.argmax(dim = 1).eq(labels).sum().item())"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 1, 28, 28])\n",
            "torch.Size([10])\n",
            "tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8])\n",
            "tensor([8, 7, 0, 8, 2, 1, 8, 7, 6, 1])\n",
            "tensor([1, 0, 0, 1, 0, 0, 1, 0, 0, 0], dtype=torch.uint8)\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-aJzrZ9vutD",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUf0femkv0fI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0d267766-7d4e-4e51-a1ac-0412ee37f09e"
      },
      "source": [
        "# turn on computation graph\n",
        "torch.set_grad_enabled(True)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size = 1000, shuffle = True)\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "preds = network(images)\n",
        "\n",
        "# defining the loss function\n",
        "loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "print('Loss before Training: {}'.format(loss.item()))\n",
        "\n",
        "# define a function to find the number of correct predictions\n",
        "def correct_predictions(pred, label):\n",
        "    return pred.argmax(dim = 1).eq(label).sum().item()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss before Training: 2.3105945587158203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XntIxex70R2W",
        "colab_type": "text"
      },
      "source": [
        "### Calculating the Gradients\n",
        "The computation graph is then used by PyTorch to calculate the gradients of the loss function with respect to the network's weights. The gradients are tensors that are accessible in the grad (short for gradient) attribute of the weight tensor of each layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g0GodMF0TZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "56d5c28a-0650-4aea-8df7-97ed1ff2a2a1"
      },
      "source": [
        "# since we have not calculated the gradients yet, they are none\n",
        "print(network.conv1.weight.grad)\n",
        "\n",
        "# To calculate the gradients, we call the backward() method on the loss tensor, like so:\n",
        "loss.backward()\n",
        "\n",
        "# print the shape of the gradients of conv1\n",
        "print(network.conv1.weight.grad.shape)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "torch.Size([6, 1, 5, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFUd0HLe1vQI",
        "colab_type": "text"
      },
      "source": [
        "### Updating the weights (optimize)\n",
        "These gradients are used by the optimizer to update the respective weights. To create our optimizer, we use the torch.optim package that has many optimization algorithm implementations that we can use. We'll use Adam for our example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4joLQMfv15ZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create an instance of Adam optimizer\n",
        "# we are passing network.parameters() as it contains all the network's variables\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
        "\n",
        "# Updating the weights\n",
        "optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kXaBO9U2cCb",
        "colab_type": "text"
      },
      "source": [
        "When the step() function is called, the optimizer updates the weights using the gradients that are stored in the network's parameters. This means that we should expect our loss to be reduced if we pass the same batch through the network again. Checking this, we can see that this is indeed the case:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWMM6rfg2dW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7e1909fe-70ef-48b8-b2ed-66d51a41f8d8"
      },
      "source": [
        "preds = network(images)\n",
        "\n",
        "# defining the loss function\n",
        "loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "print('Loss after 1 step of optimization: {}'.format(loss.item()))\n",
        "\n",
        "print(correct_predictions(preds, labels))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss after 1 step of optimization: 2.2929439544677734\n",
            "94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N4yAomn3uO0",
        "colab_type": "text"
      },
      "source": [
        "## Create a training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiMMalhB3z7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        },
        "outputId": "f37d0840-480b-4176-de2d-13c53e76b64e"
      },
      "source": [
        "num_epochs = 100\n",
        "\n",
        "train_steps = 1\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size = 60000, shuffle = True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    train_loss = 0\n",
        "    \n",
        "    for step in range(1,train_steps+1):\n",
        "        \n",
        "        images, labels = next(iter(train_loader))\n",
        "        \n",
        "        preds = network(images)\n",
        "        \n",
        "        correct_preds = correct_predictions(preds, labels)\n",
        "        \n",
        "        train_loss_step = F.cross_entropy(preds, labels)\n",
        "        \n",
        "        optimizer = optim.Adam(network.parameters(), lr = 0.001)\n",
        "        \n",
        "        # clear all the gradients before calculating the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # calculate the gradients\n",
        "        train_loss_step.backward()\n",
        "        \n",
        "        # update the parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += train_loss_step\n",
        "        \n",
        "    train_loss /= train_steps\n",
        "    print('Epoch: {}   Train Loss: {}  Correct Predictions: {}/60000'.format(epoch,train_loss, correct_preds))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0   Train Loss: 1.7009385824203491  Correct Predictions: 17929/60000\n",
            "Epoch: 1   Train Loss: 1.5319856405258179  Correct Predictions: 24268/60000\n",
            "Epoch: 2   Train Loss: 1.4026206731796265  Correct Predictions: 29690/60000\n",
            "Epoch: 3   Train Loss: 1.310050368309021  Correct Predictions: 33500/60000\n",
            "Epoch: 4   Train Loss: 1.2438098192214966  Correct Predictions: 35518/60000\n",
            "Epoch: 5   Train Loss: 1.1926342248916626  Correct Predictions: 36122/60000\n",
            "Epoch: 6   Train Loss: 1.148433804512024  Correct Predictions: 36413/60000\n",
            "Epoch: 7   Train Loss: 1.109778881072998  Correct Predictions: 36622/60000\n",
            "Epoch: 8   Train Loss: 1.0771751403808594  Correct Predictions: 37350/60000\n",
            "Epoch: 9   Train Loss: 1.0466846227645874  Correct Predictions: 37405/60000\n",
            "Epoch: 10   Train Loss: 1.0298590660095215  Correct Predictions: 38023/60000\n",
            "Epoch: 11   Train Loss: 1.017913579940796  Correct Predictions: 37535/60000\n",
            "Epoch: 12   Train Loss: 1.0118286609649658  Correct Predictions: 38213/60000\n",
            "Epoch: 13   Train Loss: 1.002448320388794  Correct Predictions: 37729/60000\n",
            "Epoch: 14   Train Loss: 0.996250569820404  Correct Predictions: 38530/60000\n",
            "Epoch: 15   Train Loss: 0.9886884689331055  Correct Predictions: 37868/60000\n",
            "Epoch: 16   Train Loss: 0.982962429523468  Correct Predictions: 38789/60000\n",
            "Epoch: 17   Train Loss: 0.9765332937240601  Correct Predictions: 38031/60000\n",
            "Epoch: 18   Train Loss: 0.9708585143089294  Correct Predictions: 38981/60000\n",
            "Epoch: 19   Train Loss: 0.9648634195327759  Correct Predictions: 38217/60000\n",
            "Epoch: 20   Train Loss: 0.9592260122299194  Correct Predictions: 39191/60000\n",
            "Epoch: 21   Train Loss: 0.9537045359611511  Correct Predictions: 38397/60000\n",
            "Epoch: 22   Train Loss: 0.9477405548095703  Correct Predictions: 39427/60000\n",
            "Epoch: 23   Train Loss: 0.9428380131721497  Correct Predictions: 38595/60000\n",
            "Epoch: 24   Train Loss: 0.9376522898674011  Correct Predictions: 39607/60000\n",
            "Epoch: 25   Train Loss: 0.9328778386116028  Correct Predictions: 38685/60000\n",
            "Epoch: 26   Train Loss: 0.9284793138504028  Correct Predictions: 39841/60000\n",
            "Epoch: 27   Train Loss: 0.9240691661834717  Correct Predictions: 38944/60000\n",
            "Epoch: 28   Train Loss: 0.9199169874191284  Correct Predictions: 40049/60000\n",
            "Epoch: 29   Train Loss: 0.915885865688324  Correct Predictions: 39129/60000\n",
            "Epoch: 30   Train Loss: 0.9121277928352356  Correct Predictions: 40229/60000\n",
            "Epoch: 31   Train Loss: 0.9085227847099304  Correct Predictions: 39238/60000\n",
            "Epoch: 32   Train Loss: 0.904829740524292  Correct Predictions: 40417/60000\n",
            "Epoch: 33   Train Loss: 0.9017723798751831  Correct Predictions: 39282/60000\n",
            "Epoch: 34   Train Loss: 0.8982647657394409  Correct Predictions: 40599/60000\n",
            "Epoch: 35   Train Loss: 0.8954499363899231  Correct Predictions: 39387/60000\n",
            "Epoch: 36   Train Loss: 0.8920877575874329  Correct Predictions: 40775/60000\n",
            "Epoch: 37   Train Loss: 0.889321506023407  Correct Predictions: 39562/60000\n",
            "Epoch: 38   Train Loss: 0.8859406113624573  Correct Predictions: 40937/60000\n",
            "Epoch: 39   Train Loss: 0.8833475112915039  Correct Predictions: 39686/60000\n",
            "Epoch: 40   Train Loss: 0.8802754282951355  Correct Predictions: 41091/60000\n",
            "Epoch: 41   Train Loss: 0.8775844573974609  Correct Predictions: 39817/60000\n",
            "Epoch: 42   Train Loss: 0.8744677901268005  Correct Predictions: 41257/60000\n",
            "Epoch: 43   Train Loss: 0.8719068765640259  Correct Predictions: 39911/60000\n",
            "Epoch: 44   Train Loss: 0.8688622117042542  Correct Predictions: 41398/60000\n",
            "Epoch: 45   Train Loss: 0.8664324879646301  Correct Predictions: 40041/60000\n",
            "Epoch: 46   Train Loss: 0.8633260130882263  Correct Predictions: 41518/60000\n",
            "Epoch: 47   Train Loss: 0.8610029220581055  Correct Predictions: 40229/60000\n",
            "Epoch: 48   Train Loss: 0.8578129410743713  Correct Predictions: 41691/60000\n",
            "Epoch: 49   Train Loss: 0.8556075096130371  Correct Predictions: 40316/60000\n",
            "Epoch: 50   Train Loss: 0.8523201942443848  Correct Predictions: 41873/60000\n",
            "Epoch: 51   Train Loss: 0.8504208922386169  Correct Predictions: 40428/60000\n",
            "Epoch: 52   Train Loss: 0.84707111120224  Correct Predictions: 41998/60000\n",
            "Epoch: 53   Train Loss: 0.8453168869018555  Correct Predictions: 40562/60000\n",
            "Epoch: 54   Train Loss: 0.8418681025505066  Correct Predictions: 42120/60000\n",
            "Epoch: 55   Train Loss: 0.8403735756874084  Correct Predictions: 40662/60000\n",
            "Epoch: 56   Train Loss: 0.8368378281593323  Correct Predictions: 42197/60000\n",
            "Epoch: 57   Train Loss: 0.8354639410972595  Correct Predictions: 40795/60000\n",
            "Epoch: 58   Train Loss: 0.8318471312522888  Correct Predictions: 42303/60000\n",
            "Epoch: 59   Train Loss: 0.8306464552879333  Correct Predictions: 40865/60000\n",
            "Epoch: 60   Train Loss: 0.826982855796814  Correct Predictions: 42408/60000\n",
            "Epoch: 61   Train Loss: 0.8260117769241333  Correct Predictions: 40946/60000\n",
            "Epoch: 62   Train Loss: 0.8222025632858276  Correct Predictions: 42528/60000\n",
            "Epoch: 63   Train Loss: 0.821377694606781  Correct Predictions: 41024/60000\n",
            "Epoch: 64   Train Loss: 0.817513644695282  Correct Predictions: 42643/60000\n",
            "Epoch: 65   Train Loss: 0.8168363571166992  Correct Predictions: 41149/60000\n",
            "Epoch: 66   Train Loss: 0.8129048943519592  Correct Predictions: 42730/60000\n",
            "Epoch: 67   Train Loss: 0.8123173117637634  Correct Predictions: 41245/60000\n",
            "Epoch: 68   Train Loss: 0.8080856800079346  Correct Predictions: 42835/60000\n",
            "Epoch: 69   Train Loss: 0.8078861832618713  Correct Predictions: 41338/60000\n",
            "Epoch: 70   Train Loss: 0.8032934665679932  Correct Predictions: 42919/60000\n",
            "Epoch: 71   Train Loss: 0.803342878818512  Correct Predictions: 41440/60000\n",
            "Epoch: 72   Train Loss: 0.7985828518867493  Correct Predictions: 43003/60000\n",
            "Epoch: 73   Train Loss: 0.7989386916160583  Correct Predictions: 41526/60000\n",
            "Epoch: 74   Train Loss: 0.7940739989280701  Correct Predictions: 43093/60000\n",
            "Epoch: 75   Train Loss: 0.7946702837944031  Correct Predictions: 41643/60000\n",
            "Epoch: 76   Train Loss: 0.7896662950515747  Correct Predictions: 43143/60000\n",
            "Epoch: 77   Train Loss: 0.7904744148254395  Correct Predictions: 41746/60000\n",
            "Epoch: 78   Train Loss: 0.7856101393699646  Correct Predictions: 43198/60000\n",
            "Epoch: 79   Train Loss: 0.7864509224891663  Correct Predictions: 41802/60000\n",
            "Epoch: 80   Train Loss: 0.7812819480895996  Correct Predictions: 43261/60000\n",
            "Epoch: 81   Train Loss: 0.7824410200119019  Correct Predictions: 41896/60000\n",
            "Epoch: 82   Train Loss: 0.7771627306938171  Correct Predictions: 43331/60000\n",
            "Epoch: 83   Train Loss: 0.7784962058067322  Correct Predictions: 41941/60000\n",
            "Epoch: 84   Train Loss: 0.7731112241744995  Correct Predictions: 43392/60000\n",
            "Epoch: 85   Train Loss: 0.7746340036392212  Correct Predictions: 42036/60000\n",
            "Epoch: 86   Train Loss: 0.7694585919380188  Correct Predictions: 43447/60000\n",
            "Epoch: 87   Train Loss: 0.7709500193595886  Correct Predictions: 42092/60000\n",
            "Epoch: 88   Train Loss: 0.7655391097068787  Correct Predictions: 43517/60000\n",
            "Epoch: 89   Train Loss: 0.7674016952514648  Correct Predictions: 41916/60000\n",
            "Epoch: 90   Train Loss: 0.761959969997406  Correct Predictions: 43550/60000\n",
            "Epoch: 91   Train Loss: 0.7636491060256958  Correct Predictions: 41883/60000\n",
            "Epoch: 92   Train Loss: 0.7579545974731445  Correct Predictions: 43585/60000\n",
            "Epoch: 93   Train Loss: 0.7597571015357971  Correct Predictions: 41960/60000\n",
            "Epoch: 94   Train Loss: 0.7540513277053833  Correct Predictions: 43640/60000\n",
            "Epoch: 95   Train Loss: 0.7560209035873413  Correct Predictions: 41999/60000\n",
            "Epoch: 96   Train Loss: 0.750373899936676  Correct Predictions: 43697/60000\n",
            "Epoch: 97   Train Loss: 0.7523358464241028  Correct Predictions: 42079/60000\n",
            "Epoch: 98   Train Loss: 0.7467381358146667  Correct Predictions: 43736/60000\n",
            "Epoch: 99   Train Loss: 0.7487431168556213  Correct Predictions: 42166/60000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}