{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VLocnet TF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkalim/Tensorflow-/blob/master/VLocnet_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj_WEDGecayE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "\n",
        "_BATCH_NORM_DECAY = 0.997\n",
        "_BATCH_NORM_EPSILON = 1e-5\n",
        "\n",
        "################################################################################\n",
        "# Helper Functions\n",
        "################################################################################\n",
        "\n",
        "# Performs a batch normalization using a standard set of parameters.\n",
        "def batch_norm(inputs, training, name = 'batch_norm'):\n",
        "    with tf.name_scope(name):\n",
        "        # here axis = 3 (channel last format)\n",
        "        return tf.layers.batch_normalization(\n",
        "            inputs=inputs, axis=3,\n",
        "            momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, center=True,\n",
        "            scale=True, training=training, fused=True, reuse = False)\n",
        "\n",
        "def maxpool_2d(inputs, kernel = 2, stride = 2, name = 'maxpool_2d'):\n",
        "    with tf.name_scope(name):\n",
        "        return tf.nn.max_pool(inputs, ksize=[1, kernel, kernel, 1], strides=[1, stride, stride, 1], padding='SAME')\n",
        "\n",
        "\n",
        "def fixed_padding(inputs, kernel_size, name = 'fixed_padding'):\n",
        "    \"\"\"Pads the input along the spatial dimensions independently of input size.\n",
        "    Args:\n",
        "        inputs: A tensor of size [batch, height_in, width_in, channels]\n",
        "        \n",
        "        kernel_size: The kernel size for conv2d or max_pool2d operation\n",
        "                 \n",
        "    Returns:\n",
        "        A tensor with the same format as the input with the data either intact\n",
        "        (if kernel_size == 1) or padded (if kernel_size > 1)\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "        \n",
        "        pad_total = kernel_size - 1\n",
        "        pad_beg = pad_total // 2\n",
        "        pad_end = pad_total - pad_beg\n",
        "\n",
        "        padded_inputs = tf.pad(tensor=inputs, paddings=[[0, 0], [pad_beg, pad_end], [pad_beg, pad_end], [0, 0]])\n",
        "        return padded_inputs\n",
        "\n",
        "def conv2d_fixed_padding(inputs, filters, kernel_size, strides, name = 'conv2d_fp'):\n",
        "    \n",
        "    with tf.name_scope(name):\n",
        "        # inputs will be of shape [-1,row,col,filters_in]\n",
        "        filters_in = int(inputs.shape[3])\n",
        "\n",
        "        # if stride > 1 then pad the input with the kernel size to obtain fixed padding\n",
        "        if strides > 1:\n",
        "            inputs = fixed_padding(inputs, kernel_size)\n",
        "            \n",
        "        with tf.variable_scope('weights', reuse=True):    \n",
        "            w = tf.Variable(tf.truncated_normal([kernel_size, kernel_size, filters_in, filters], stddev=0.1), name=\"W\")\n",
        "\n",
        "        output = tf.nn.conv2d(inputs, w, strides=[1, strides, strides, 1], padding=('SAME' if strides == 1 else 'VALID'))  \n",
        "\n",
        "        return output  \n",
        "\n",
        "################################################################################\n",
        "# ResNet block definitions.\n",
        "################################################################################\n",
        "def bottleneck_block(inputs, filters, training, projection_shortcut, strides, name = 'bottleneck'):\n",
        "    \"\"\"A single block for ResNet v1, with a bottleneck.\n",
        "    Similar to _building_block_v1(), except using the \"bottleneck\" blocks.\n",
        "    Convolution then batch normalization then ReLU.\n",
        "      \n",
        "    Args:\n",
        "        inputs: A tensor of size [batch, height_in, width_in, channels]\n",
        "        \n",
        "        filters: The number of filters for the convolutions.\n",
        "        \n",
        "        training: A Boolean for whether the model is in training or inference\n",
        "                    mode. Needed for batch normalization.\n",
        "                    \n",
        "        projection_shortcut: The function to use for projection shortcuts\n",
        "                        (typically a 1x1 convolution when downsampling the input).\n",
        "                        \n",
        "        strides: The block's stride. If greater than 1, this block will ultimately\n",
        "                 downsample the input.\n",
        "    Returns:\n",
        "        The output tensor of the block; shape should match inputs.\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "        shortcut = inputs\n",
        "\n",
        "        if projection_shortcut is not None:\n",
        "            shortcut = projection_shortcut(inputs)\n",
        "            shortcut = batch_norm(inputs=shortcut, training=training)\n",
        "\n",
        "        inputs = conv2d_fixed_padding(inputs = inputs, filters = filters, kernel_size=1, strides=1)\n",
        "        inputs = batch_norm(inputs, training)\n",
        "        inputs = tf.nn.relu(inputs)\n",
        "\n",
        "        inputs = conv2d_fixed_padding(inputs = inputs, filters = filters, kernel_size=3, strides=strides)\n",
        "        inputs = batch_norm(inputs, training)\n",
        "        inputs = tf.nn.relu(inputs)\n",
        "\n",
        "        inputs = conv2d_fixed_padding(inputs = inputs, filters = 4 * filters, kernel_size=1, strides=1)\n",
        "        inputs = batch_norm(inputs, training)\n",
        "\n",
        "        inputs += shortcut\n",
        "        output = tf.nn.relu(inputs)\n",
        "\n",
        "        return output\n",
        "\n",
        "def stage(inputs, filters, blocks, strides, training, name = 'stage'):\n",
        "    \"\"\"Creates one layer of blocks for the ResNet model.\n",
        "    Args:\n",
        "        inputs: A tensor of size [batch, height_in, width_in, channels]\n",
        "        \n",
        "        filters: The number of filters for the first convolution of the layer\n",
        "        \n",
        "        blocks: The number of blocks contained in the layer.\n",
        "        \n",
        "        strides: The stride to use for the first convolution of the layer. If greater than 1, \n",
        "                 this layer will ultimately downsample the input.\n",
        "                 \n",
        "        training: Boolean, whether we are currently training the model. Needed for batch norm.\n",
        "        \n",
        "        name: A string name for the tensor output of the block layer.\n",
        " \n",
        "    Returns:\n",
        "        The output tensor of the block layer.\n",
        "    \"\"\"\n",
        "    \n",
        "    with tf.name_scope(name):\n",
        "\n",
        "        # Bottleneck blocks end with 4 x filters \n",
        "        filters_out = filters * 4 \n",
        "\n",
        "        def projection_shortcut(inputs):\n",
        "            with tf.name_scope('projection_shortcut'):           \n",
        "                # here number of filters = filters_out to match the shape of the output\n",
        "                return conv2d_fixed_padding(inputs = inputs, filters = filters_out, kernel_size = 1, strides = strides)\n",
        "\n",
        "        # we can make the entire resnet model using bottleneck blocks by selecting block_fn as bottleneck_block\n",
        "\n",
        "        # Only the first block per block_layer uses projection_shortcut and strides\n",
        "        inputs = bottleneck_block(inputs, filters, training, projection_shortcut, strides, name = 'block_1')\n",
        "\n",
        "        for i in range(1, blocks):\n",
        "            # other blocks in a layer do not use projecting shortcuts and they use stride = 1\n",
        "            inputs = bottleneck_block(inputs, filters, training, projection_shortcut = None, strides = 1, name = 'block_{}'.format(i+1))\n",
        "\n",
        "        # Naming the output tensor    \n",
        "        output = tf.identity(inputs, name + '_out')  \n",
        "\n",
        "        return output\n",
        "\n",
        "class resnet(object):\n",
        "# Base class for building the Resnet Model\n",
        "\n",
        "    def __init__(self, num_classes, num_filters,kernel_size,conv_stride, first_pool_size, first_pool_stride, block_sizes, block_strides):\n",
        "        \n",
        "        \"\"\"Creates a model for classifying an image.\n",
        "        Args:\n",
        "\n",
        "            num_classes: The number of classes used as labels.\n",
        "      \n",
        "            num_filters: The number of filters to use for the first block layer of the model. \n",
        "                   This number is then doubled for each subsequent block layer\n",
        "                   \n",
        "            kernel_size: The kernel size to use for convolution.\n",
        "      \n",
        "            conv_stride: stride size for the initial convolutional layer\n",
        "      \n",
        "            first_pool_size: Pool size to be used for the first pooling layer.\n",
        "                       If none, the first pooling layer is skipped.\n",
        "                       \n",
        "            first_pool_stride: stride size for the first pooling layer. \n",
        "                         Not used if first_pool_size is None.\n",
        "                         \n",
        "            block_sizes: A list containing n values, where n is the number of sets of\n",
        "                   block layers desired. Each value should be the number of blocks in the i-th set.\n",
        "        \n",
        "            block_strides: List of integers representing the desired stride size for\n",
        "                     each of the sets of block layers. Should be same length as block_sizes.\n",
        "        \"\"\"\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.conv_stride = conv_stride\n",
        "        self.first_pool_size = first_pool_size\n",
        "        self.first_pool_stride = first_pool_stride\n",
        "        self.block_sizes = block_sizes\n",
        "        self.block_strides = block_strides\n",
        "\n",
        "    def __call__(self, inputs, training, name):\n",
        "        \"\"\"Add operations to classify a batch of input images.\n",
        "        Args:\n",
        "            inputs: A Tensor representing a batch of input images.\n",
        "            \n",
        "            training: A boolean. Set to True to add operations required only when\n",
        "                      training the classifier.\n",
        "        Returns:\n",
        "            A logits Tensor with shape [<batch_size>, self.num_classes].\n",
        "        \"\"\"\n",
        "\n",
        "        with tf.name_scope(name):\n",
        "            \n",
        "            ######################################### Stage:1 ##########################################\n",
        "            with tf.name_scope('stage_1'):\n",
        "            \n",
        "                inputs = conv2d_fixed_padding(inputs=inputs, filters=self.num_filters, kernel_size=self.kernel_size, strides=self.conv_stride)\n",
        "                inputs = tf.identity(inputs, 'initial_conv')\n",
        "                inputs = batch_norm(inputs, training)\n",
        "                inputs = tf.nn.relu(inputs)\n",
        "\n",
        "                if self.first_pool_size:\n",
        "                    inputs = tf.compat.v1.layers.max_pooling2d(inputs=inputs, pool_size=self.first_pool_size, strides=self.first_pool_stride, padding='SAME')\n",
        "                    inputs = tf.identity(inputs, 'initial_max_pool')\n",
        "            \n",
        "            ######################################### Stage:2-n ##########################################\n",
        "            for i, num_blocks in enumerate(self.block_sizes[:-1]):\n",
        "                  \n",
        "                num_filters = self.num_filters * (2**i)\n",
        "                inputs = stage(inputs=inputs, filters = num_filters, blocks=num_blocks, strides=self.block_strides[i], training = training, name='stage_{}'.format(i + 2))\n",
        "            \n",
        "            return inputs\n",
        "               \n",
        "            \n",
        "class vlocnet(object):\n",
        "    \n",
        "    def __init__(self, num_classes, num_filters,kernel_size,conv_stride, first_pool_size, first_pool_stride, block_sizes, block_strides):\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.conv_stride = conv_stride\n",
        "        self.first_pool_size = first_pool_size\n",
        "        self.first_pool_stride = first_pool_stride\n",
        "        self.block_sizes = block_sizes\n",
        "        self.block_strides = block_strides\n",
        "        \n",
        "    \n",
        "        self.current_stream = resnet( self.num_classes, self.num_filters,\n",
        "               self.kernel_size, self.conv_stride, self.first_pool_size, self.first_pool_stride,\n",
        "               self.block_sizes, self.block_strides)\n",
        "    \n",
        "        self.prev_stream = resnet( self.num_classes, self.num_filters,\n",
        "               self.kernel_size, self.conv_stride, self.first_pool_size, self.first_pool_stride,\n",
        "               self.block_sizes, self.block_strides)\n",
        "        \n",
        "    def __call__(self, current_frame, prev_frame, training):   \n",
        "        \n",
        "        with tf.name_scope('Model'):\n",
        "    \n",
        "            x = self.current_stream(current_frame, training, name = 'current_stream')\n",
        "            y = self.prev_stream(prev_frame, training, name = 'prev_stream')\n",
        "\n",
        "            con = tf.concat([x,y], axis = 3)\n",
        "\n",
        "            ################# Stage: 5 ##########################\n",
        "            num_filters = int(con.shape[3])\n",
        "            inputs = stage(inputs=con, filters = num_filters, blocks=self.block_sizes[-1], strides=self.block_strides[-1], training = training, name='stage_5')\n",
        "\n",
        "\n",
        "            with tf.name_scope('Output_Stage'):\n",
        "\n",
        "                    # axis of pooling as we use channel last\n",
        "                    axes = [1, 2]\n",
        "                    \n",
        "                    # global average pooling \n",
        "                    inputs = tf.reduce_mean(input_tensor = inputs, axis=axes, keepdims = True)\n",
        "                    \n",
        "                    inputs = tf.squeeze(inputs, axes)\n",
        "                    \n",
        "                    inputs = tf.layers.dense(inputs=inputs, units = 1024)\n",
        "                    \n",
        "                    position = tf.layers.dense(inputs=inputs, units = 3)\n",
        "                    orientation = tf.layers.dense(inputs=inputs, units = 4)\n",
        "                    \n",
        "                    position = tf.identity(position, 'position')\n",
        "                    orientation = tf.identity(orientation, 'orientation')\n",
        "                    \n",
        "                    return position, orientation \n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H7pvo7aczAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = vlocnet( num_classes = 10, num_filters = 64,\n",
        "               kernel_size = 7, conv_stride = 2, first_pool_size = 3, first_pool_stride = 2,\n",
        "               block_sizes = [3,4,6,3], block_strides =[1,2,2,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJWeVkQCcvcI",
        "colab_type": "code",
        "outputId": "d1c101db-02d4-4a8e-d566-1a8c890201da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "with tf.name_scope(\"Placeholders\"):    \n",
        "    # Defining the features and labels placeholders\n",
        "    current_frame = tf.placeholder(tf.float32 ,shape = [None ,224,224,3] , name='current_frame')\n",
        "    prev_frame = tf.placeholder(tf.float32 ,shape = [None ,224,224,3] , name='prev_frame')\n",
        "    \n",
        "    Y = tf.placeholder(tf.float32,shape = [None , 10], name='Y')\n",
        "    train = tf.placeholder(tf.bool, name = 'train')\n",
        " \n",
        "# Create the CNN model\n",
        "# keep_prob is the probability to keep a node during training\n",
        "position, orientation = model(current_frame,prev_frame, train)\n",
        "'''\n",
        "with tf.name_scope(\"Loss\"):    \n",
        "    # Defining the loss function\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=Y))\n",
        "    tf.summary.scalar(\"Loss\",loss)\n",
        "\n",
        "with tf.name_scope(\"Optimizer\"):\n",
        "    # Defining the optimization function\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)\n",
        "\n",
        "with tf.name_scope(\"Accuracy\"):    \n",
        "    # The prediction is correct when Y equals pred\n",
        "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
        "\n",
        "    # Defining the accuracy\n",
        "    # Type casting the prediction to float value and averaging over the entire set\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    tf.summary.scalar(\"Accuracy\",accuracy)\n",
        "\n",
        "'''\n",
        "with tf.name_scope(\"Initializer\"):    \n",
        "    # Defining the variable initialisation function\n",
        "    init = tf.global_variables_initializer()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-1-d542e5dfefce>:22: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.batch_normalization instead.\n",
            "WARNING:tensorflow:From <ipython-input-1-d542e5dfefce>:218: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.max_pooling2d instead.\n",
            "WARNING:tensorflow:From <ipython-input-1-d542e5dfefce>:276: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8geLDitodI7R",
        "colab_type": "code",
        "outputId": "6bd5e788-1f3e-488b-a362-a02b3bc0048d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        }
      },
      "source": [
        "!pip install -q tf-nightly-2.0-preview\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    # Initialise the variables\n",
        "    sess.run(init)\n",
        "    \n",
        "    # Clear any prior data in logs\n",
        "    !rm -rf 'logs'\n",
        "    \n",
        "    # create a train summary writer\n",
        "    writer = tf.summary.FileWriter('logs' , sess.graph)\n",
        "\n",
        "    # Load Tensorboard at the two directories\n",
        "    %tensorboard --logdir 'logs'   "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}